"""
VideoEditor: Maneja la edici√≥n y renderizado de videos con subt√≠tulos usando Whisper.
Versi√≥n corregida con espera de archivos para OneDrive y rutas absolutas.
"""

import os
import time
import shutil
import tempfile
import subprocess
import unicodedata
import re
from pathlib import Path
from typing import List, Dict, Any, Optional

try:
    from PIL import Image
    # Compatibilidad con Pillow 10.0+
    if not hasattr(Image, 'ANTIALIAS'):
        Image.ANTIALIAS = Image.LANCZOS
except ImportError:
    pass

# --- CONFIGURACI√ìN FORZADA DE IMAGEMAGICK (ANTES DE IMPORTAR MOVIEPY) ---
# Esto asegura que ImageMagick est√© disponible para TextClip desde el inicio
IMAGEMAGICK_BINARY = None

def _configure_imagemagick_global():
    """Configura ImageMagick globalmente antes de importar MoviePy."""
    global IMAGEMAGICK_BINARY
    
    # Intentar importar change_settings (puede no existir en versiones nuevas de MoviePy)
    try:
        from moviepy.config import change_settings
        has_change_settings = True
    except (ImportError, AttributeError):
        has_change_settings = False
    
    # Rutas est√°ndar de ImageMagick en Windows
    imagemagick_paths = [
        r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe",
        r"C:\Program Files\ImageMagick-7.1.0-Q16-HDRI\magick.exe",
        r"C:\Program Files\ImageMagick-7.0.11-Q16-HDRI\magick.exe",
        r"C:\Program Files (x86)\ImageMagick-7.1.1-Q16-HDRI\magick.exe",
        r"C:\Program Files (x86)\ImageMagick-7.1.0-Q16-HDRI\magick.exe",
        r"C:\Program Files (x86)\ImageMagick-7.0.11-Q16-HDRI\magick.exe",
        # Intentar tambi√©n con rutas comunes sin versi√≥n espec√≠fica
        r"C:\Program Files\ImageMagick\magick.exe",
        r"C:\Program Files (x86)\ImageMagick\magick.exe",
    ]
    
    # Intentar configurar ImageMagick desde rutas est√°ndar
    for path in imagemagick_paths:
        if os.path.exists(path):
            try:
                if has_change_settings:
                    change_settings({"IMAGEMAGICK_BINARY": path})
                else:
                    # Alternativa: configurar variable de entorno
                    os.environ["IMAGEMAGICK_BINARY"] = path
                IMAGEMAGICK_BINARY = path
                print(f"[ImageMagick] OK Configurado: {path}")
                return True
            except Exception as e:
                print(f"[ImageMagick] WARNING Error configurando {path}: {e}")
    
    # Si no se encontr√≥, intentar buscar en PATH del sistema
    try:
        magick_path = shutil.which("magick")
        if magick_path:
            if has_change_settings:
                change_settings({"IMAGEMAGICK_BINARY": magick_path})
            else:
                os.environ["IMAGEMAGICK_BINARY"] = magick_path
            IMAGEMAGICK_BINARY = magick_path
            print(f"[ImageMagick] OK Encontrado en PATH: {magick_path}")
            return True
    except Exception as e:
        print(f"[ImageMagick] WARNING Error buscando en PATH: {e}")
    
    # Si no se encontr√≥, intentar buscar en variables de entorno
    try:
        env_path = os.getenv("IMAGEMAGICK_BINARY") or os.getenv("MAGICK_HOME")
        if env_path:
            # Si es un directorio, agregar magick.exe
            if os.path.isdir(env_path):
                magick_exe = os.path.join(env_path, "magick.exe")
                if os.path.exists(magick_exe):
                    if has_change_settings:
                        change_settings({"IMAGEMAGICK_BINARY": magick_exe})
                    else:
                        os.environ["IMAGEMAGICK_BINARY"] = magick_exe
                    IMAGEMAGICK_BINARY = magick_exe
                    print(f"[ImageMagick] OK Encontrado en variable de entorno: {magick_exe}")
                    return True
            elif os.path.exists(env_path) and env_path.endswith(".exe"):
                if has_change_settings:
                    change_settings({"IMAGEMAGICK_BINARY": env_path})
                else:
                    os.environ["IMAGEMAGICK_BINARY"] = env_path
                IMAGEMAGICK_BINARY = env_path
                print(f"[ImageMagick] OK Encontrado en variable de entorno: {env_path}")
                return True
    except Exception as e:
        print(f"[ImageMagick] WARNING Error buscando en variables de entorno: {e}")
    
    print("[ImageMagick] WARNING ImageMagick no encontrado. Los subtitulos pueden fallar.")
    print("[ImageMagick] INFO Instala ImageMagick desde: https://imagemagick.org/script/download.php")
    print("[ImageMagick] INFO O configura la variable de entorno IMAGEMAGICK_BINARY con la ruta completa a magick.exe")
    return False

# Ejecutar configuraci√≥n global ANTES de importar MoviePy
_configure_imagemagick_global()

# Ahora s√≠ importamos MoviePy (con ImageMagick ya configurado)
from moviepy.editor import (
    VideoFileClip, AudioFileClip, CompositeVideoClip, CompositeAudioClip,
    TextClip, ImageClip, concatenate_videoclips, concatenate_audioclips
)
from moviepy.video.VideoClip import ColorClip
from moviepy.video.fx import all as vfx

# --- FIX DE EMERGENCIA PARA NUMPY (Compatibility Patch) ---
import moviepy.audio.io.ffmpeg_audiowriter
import numpy as np

# Sobrescribir la funci√≥n problem√°tica si es necesario
try:
    from moviepy.audio.AudioClip import AudioClip
    original_to_soundarray = AudioClip.to_soundarray
    
    def patched_to_soundarray(self, tt=None, fps=None, quantize=False, nbytes=2, buffersize=50000):
        if fps is None: 
            fps = self.fps
        try:
            return original_to_soundarray(self, tt, fps, quantize, nbytes, buffersize)
        except (TypeError, ValueError) as e:
            # Si falla por 0-d array o problemas de iteraci√≥n, forzamos un array v√°lido
            print(f"‚ö†Ô∏è [Numpy Fix] Error en to_soundarray, usando fallback: {e}")
            return np.zeros((1, 2), dtype=np.float32)
            
    AudioClip.to_soundarray = patched_to_soundarray
    print("[Numpy Fix] ‚úÖ Parche de compatibilidad aplicado para AudioClip.to_soundarray")
except Exception as e:
    print(f"‚ö†Ô∏è [Numpy Fix] No se pudo aplicar el parche de Numpy: {e}")
# ---------------------------------------------------------

# --- PARCHE DE METRATRON PARA FFMPEG ---
# Esto conecta el FFmpeg interno de Python con el sistema para que Whisper lo vea
FFMPEG_EXE_PATH = None  # Variable global para guardar la ruta de FFmpeg

try:
    import imageio_ffmpeg
    ffmpeg_path = os.path.dirname(imageio_ffmpeg.get_ffmpeg_exe())
    os.environ["PATH"] += os.pathsep + ffmpeg_path
    
    # Guardar la ruta completa del ejecutable para uso posterior
    FFMPEG_EXE_PATH = imageio_ffmpeg.get_ffmpeg_exe()
    os.environ["FFMPEG_BINARY"] = FFMPEG_EXE_PATH
    
    # Logging (importar logger antes de usarlo)
    from loguru import logger
    logger.success(f"‚úÖ FFmpeg puenteado exitosamente desde: {ffmpeg_path}")
except ImportError:
    # Importar logger para el warning
    from loguru import logger
    logger.warning("‚ö†Ô∏è No se pudo aplicar el puente de FFmpeg. imageio-ffmpeg no encontrado.")
except Exception as e:
    from loguru import logger
    logger.warning(f"‚ö†Ô∏è No se pudo aplicar el puente de FFmpeg: {e}")

# Ahora s√≠ importamos Whisper seguro
import whisper
# ---------------------------------------


# --- CONFIGURACI√ìN DE FORMATO (METRATRON) ---
TARGET_WIDTH = 1080
TARGET_HEIGHT = 1920
ASPECT_RATIO = TARGET_WIDTH / TARGET_HEIGHT  # 9:16


def esperar_archivo(ruta_archivo: str, intentos: int = 30, espera: float = 0.5) -> bool:
    """
    Espera a que un archivo exista y tenga contenido.
    Especialmente importante para archivos en OneDrive que pueden estar sincroniz√°ndose.
    
    Args:
        ruta_archivo: Ruta absoluta del archivo a esperar
        intentos: Cu√°ntas veces revisar√° (30 veces * 0.5s = 15 segundos m√°x)
        espera: Segundos de espera entre intentos
    
    Returns:
        True si el archivo existe y tiene contenido, False en caso contrario
    """
    logger.info(f"üîç Buscando archivo: {ruta_archivo}")
    
    # Convertir a Path para normalizaci√≥n
    ruta_archivo_path = Path(ruta_archivo)
    
    for i in range(intentos):
        # 1. Verificar si existe
        if ruta_archivo_path.exists():
            try:
                # 2. Verificar si tiene tama√±o (no est√° vac√≠o)
                size = ruta_archivo_path.stat().st_size
                if size > 0:
                    logger.success(f"‚úÖ Archivo encontrado y listo: {Path(ruta_archivo).name} ({size:,} bytes)")
                    time.sleep(0.3)  # Pausa de seguridad para liberar el 'lock' de OneDrive
                    return True
                else:
                    logger.warning(f"‚è≥ El archivo existe pero est√° vac√≠o (Intento {i+1}/{intentos})...")
            except (OSError, PermissionError) as e:
                # OneDrive puede estar bloqueando el archivo temporalmente
                logger.debug(f"‚è≥ Archivo bloqueado por OneDrive? (Intento {i+1}/{intentos}): {e}")
        else:
            logger.debug(f"‚è≥ Esperando creaci√≥n del archivo (Intento {i+1}/{intentos})...")
        
        time.sleep(espera)
    
    logger.error(f"‚ùå ERROR CR√çTICO: El archivo nunca apareci√≥ en: {ruta_archivo}")
    return False


class VideoEditor:
    """Editor de video que genera subt√≠tulos autom√°ticos con Whisper."""
    
    def __init__(self, whisper_model: str = "base", font: str = "Arial"):
        """
        Inicializa el editor de video.
        
        Args:
            whisper_model: Modelo de Whisper a usar (tiny, base, small, medium, large)
            font: Nombre de la fuente para los subt√≠tulos
        """
        # ImageMagick ya est√° configurado globalmente al inicio del archivo
        # Solo verificamos que est√© disponible y funcionando
        self.imagemagick_configured = IMAGEMAGICK_BINARY is not None
        if self.imagemagick_configured:
            logger.success(f"‚úÖ ImageMagick disponible: {IMAGEMAGICK_BINARY}")
            # Verificar que realmente funciona
            try:
                test_clip = TextClip("Test", fontsize=20, color='white').set_duration(0.1)
                test_clip.close()
                logger.success("‚úÖ ImageMagick verificado y funcionando correctamente")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è ImageMagick configurado pero fall√≥ la verificaci√≥n: {e}")
        else:
            logger.warning("‚ö†Ô∏è ImageMagick no est√° configurado. Los subt√≠tulos pueden fallar.")
            logger.info("üí° Instala ImageMagick desde: https://imagemagick.org/script/download.php")
        
        # Verificar FFmpeg antes de cargar Whisper
        self.ffmpeg_available = self._check_ffmpeg()
        
        if not self.ffmpeg_available:
            logger.warning("‚ö†Ô∏è FFmpeg no encontrado en PATH. Los subt√≠tulos se generar√°n sin Whisper.")
            logger.warning("üí° Para habilitar subt√≠tulos, instala FFmpeg: choco install ffmpeg o descarga de gyan.dev")
            self.whisper_model = None
        else:
            logger.info(f"Cargando modelo Whisper: {whisper_model}")
            try:
                self.whisper_model = whisper.load_model(whisper_model)
                logger.success("Modelo Whisper cargado")
            except Exception as e:
                logger.warning(f"No se pudo cargar Whisper: {e}. Continuando sin subt√≠tulos.")
                self.whisper_model = None
        
        # ============================================================
        # CONFIGURACI√ìN DE FUENTE PERSONALIZADA
        # ============================================================
        # Buscar fuente personalizada en assets/fonts/viral.ttf
        BASE_DIR = Path(__file__).parent.parent.resolve()
        custom_font_path = BASE_DIR / "assets" / "fonts" / "viral.ttf"
        
        if custom_font_path.exists():
            # Usar fuente personalizada con ruta absoluta
            self.font = str(custom_font_path.resolve())
            logger.success(f"‚úÖ Fuente personalizada cargada: {self.font}")
        else:
            # Usar fuente de sistema por defecto (Arial-Bold para mejor visibilidad)
            self.font = font if font != "Arial" else "Arial-Bold"
            logger.info(f"üìù Usando fuente del sistema: {self.font}")
            logger.info(f"üí° Para usar fuente personalizada, coloca 'viral.ttf' en: assets/fonts/")
        
        # Guardar ruta de fuente personalizada para referencia
        self.custom_font_path = custom_font_path if custom_font_path.exists() else None
        logger.info(f"VideoEditor inicializado (font: {self.font})")
    
    @staticmethod
    def _normalize_style_slug(style_name: Optional[str]) -> str:
        if not style_name:
            return "general"
        normalized = unicodedata.normalize("NFKD", style_name)
        ascii_text = normalized.encode("ascii", "ignore").decode("ascii").lower()
        ascii_text = ascii_text.replace("/", " ")
        tokens = [t for t in re.split(r"[^a-z0-9]+", ascii_text) if t]
        return tokens[0] if tokens else "general"
    
    @staticmethod
    def _resolve_branding_asset(style_slug: str, filename: str) -> Optional[Path]:
        """
        Resuelve la ruta de un asset de branding.
        Busca en este orden:
        1. assets/branding/filename (directamente en la ra√≠z)
        2. assets/branding/{style_slug}/filename (subcarpeta del estilo)
        3. assets/branding/general/filename (carpeta general)
        """
        base_dir = Path("assets/branding")
        if not base_dir.exists():
            return None
        
        # 1. Buscar directamente en assets/branding/ (prioridad m√°xima)
        root_path = base_dir / filename
        if root_path.exists():
            return root_path
        
        # 2. Buscar en subcarpeta del estilo espec√≠fico
        if style_slug and style_slug != "general":
            style_path = base_dir / style_slug / filename
            if style_path.exists():
                return style_path
        
        # 3. Buscar en carpeta general como fallback
        general_path = base_dir / "general" / filename
        if general_path.exists():
            return general_path
        
        return None
    
    def _load_branding_text(self, style_slug: str, filename: str) -> Optional[str]:
        asset_path = self._resolve_branding_asset(style_slug, filename)
        if asset_path:
            try:
                return asset_path.read_text(encoding="utf-8").strip()
            except Exception as exc:
                logger.warning(f"‚ö†Ô∏è No se pudo leer {asset_path}: {exc}")
        return None
    
    def _verify_imagemagick(self):
        """Verifica que ImageMagick est√© configurado correctamente."""
        global IMAGEMAGICK_BINARY
        
        if IMAGEMAGICK_BINARY and os.path.exists(IMAGEMAGICK_BINARY):
            try:
                # Intentar crear un TextClip de prueba para verificar que funciona
                test_clip = TextClip("Test", fontsize=20, color='white').set_duration(0.1)
                test_clip.close()
                logger.success("‚úÖ ImageMagick verificado y funcionando correctamente")
                return True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è ImageMagick configurado pero fall√≥ la verificaci√≥n: {e}")
                return False
        else:
            logger.warning("‚ö†Ô∏è ImageMagick no est√° disponible. Los subt√≠tulos no funcionar√°n.")
            return False
    
    def _check_ffmpeg(self) -> bool:
        """
        Verifica si FFmpeg est√° disponible en el sistema.
        Usa el FFmpeg vinculado por Metratron si est√° disponible.
        
        Returns:
            True si FFmpeg est√° disponible, False en caso contrario
        """
        try:
            # Si tenemos la ruta del FFmpeg de imageio_ffmpeg, usarla directamente
            if FFMPEG_EXE_PATH and os.path.exists(FFMPEG_EXE_PATH):
                result = subprocess.run(
                    [FFMPEG_EXE_PATH, "-version"],
                    capture_output=True,
                    timeout=5,
                    text=True
                )
                if result.returncode == 0:
                    logger.success(f"‚úÖ FFmpeg verificado: {FFMPEG_EXE_PATH}")
                    return True
            
            # Intentar buscar en el PATH (por si acaso ya estaba instalado)
            result = subprocess.run(
                ["ffmpeg", "-version"],
                capture_output=True,
                timeout=5,
                text=True
            )
            if result.returncode == 0:
                logger.success("‚úÖ FFmpeg encontrado en PATH del sistema")
                return True
                
            return False
        except (FileNotFoundError, subprocess.TimeoutExpired, Exception) as e:
            logger.debug(f"FFmpeg no encontrado: {e}")
            return False
    
    def _resize_to_format(self, clip: VideoFileClip, target_width: int, target_height: int) -> VideoFileClip:
        """
        Redimensiona un clip de video al formato y resoluci√≥n especificados.
        Mantiene el aspecto sin distorsi√≥n usando crop/zoom inteligente (Center Crop).
        
        Args:
            clip: Clip de video a redimensionar
            target_width: Ancho objetivo
            target_height: Alto objetivo
        
        Returns:
            Clip redimensionado al formato especificado
        """
        try:
            original_width, original_height = clip.size
            original_aspect = original_width / original_height
            target_aspect = target_width / target_height
            
            logger.debug(f"Redimensionando video: {original_width}x{original_height} -> {target_width}x{target_height}")
            
            # Si el video ya est√° en el formato correcto
            if abs(original_width - target_width) < 10 and abs(original_height - target_height) < 10:
                logger.debug("Video ya est√° en formato correcto, omitiendo redimensionamiento")
                return clip
            
            # Si el video es m√°s horizontal que el target, hacer crop centrado horizontal
            if original_aspect > target_aspect:
                # Video es m√°s ancho: recortar los lados (Center Crop)
                new_width = int(original_height * target_aspect)
                x_center = original_width / 2
                x1 = max(0, int(x_center - new_width / 2))
                x2 = min(original_width, int(x_center + new_width / 2))
                
                clip = clip.crop(x1=x1, x2=x2)
                logger.debug(f"Crop horizontal (Center): x1={x1}, x2={x2}, nuevo tama√±o: {clip.size}")
            
            # Si el video es m√°s vertical que el target, hacer crop centrado vertical
            elif original_aspect < target_aspect:
                # Video es m√°s alto: recortar arriba/abajo (Center Crop)
                new_height = int(original_width / target_aspect)
                y_center = original_height / 2
                y1 = max(0, int(y_center - new_height / 2))
                y2 = min(original_height, int(y_center + new_height / 2))
                
                clip = clip.crop(y1=y1, y2=y2)
                logger.debug(f"Crop vertical (Center): y1={y1}, y2={y2}, nuevo tama√±o: {clip.size}")
            
            # Redimensionar al tama√±o objetivo exacto
            clip = clip.resize((target_width, target_height))
            logger.debug(f"Video redimensionado a {target_width}x{target_height}")
            
            return clip
            
        except Exception as e:
            logger.warning(f"Error redimensionando video, usando tama√±o original: {e}")
            return clip
    
    def _resize_to_vertical_format(self, clip: VideoFileClip) -> VideoFileClip:
        """
        Redimensiona un clip de video al formato vertical 9:16 (1080x1920).
        Mantiene compatibilidad con c√≥digo existente.
        
        Args:
            clip: Clip de video a redimensionar
        
        Returns:
            Clip redimensionado al formato vertical
        """
        return self._resize_to_format(clip, TARGET_WIDTH, TARGET_HEIGHT)
    
    def _apply_color_grading(self, clip: VideoFileClip, enable_grading: bool = True) -> VideoFileClip:
        """
        Aplica efectos de color grading profesional al clip.
        
        Args:
            clip: Clip de video a procesar
            enable_grading: Si True, aplica los efectos. Si False, retorna el clip sin modificar
        
        Returns:
            Clip con efectos aplicados
        """
        if not enable_grading:
            return clip
        
        try:
            logger.debug("Aplicando color grading...")
            
            # 1. Correcci√≥n de color: Aumentar saturaci√≥n y contraste sutilmente
            # Intentar usar colorx si est√° disponible
            try:
                # colorx: factor > 1.0 aumenta saturaci√≥n/brillo
                clip = clip.fx(vfx.colorx, 1.08)  # Aumento sutil del 8%
            except (AttributeError, TypeError):
                # Si colorx no est√° disponible, intentar con multiply_color
                try:
                    clip = clip.fx(vfx.multiply_color, 1.08)
                except (AttributeError, TypeError):
                    logger.debug("colorx/multiply_color no disponible, saltando correcci√≥n de saturaci√≥n")
            
            # 2. Aumentar contraste
            try:
                # lum_contrast: (lum, contrast, contrast_thr)
                # lum: luminosidad (0 = sin cambio)
                # contrast: contraste (1.0 = sin cambio, >1.0 = m√°s contraste)
                # contrast_thr: umbral de contraste
                clip = clip.fx(vfx.lum_contrast, 0, 0.08, 1.15)  # Aumento sutil de contraste
            except (AttributeError, TypeError):
                # Si lum_contrast no est√° disponible, intentar con multiply_contrast
                try:
                    clip = clip.fx(vfx.multiply_contrast, 1.15)
                except (AttributeError, TypeError):
                    logger.debug("lum_contrast/multiply_contrast no disponible, saltando correcci√≥n de contraste")
            
            logger.debug("Color grading aplicado exitosamente")
            
        except Exception as e:
            logger.warning(f"Error aplicando color grading: {e}. Continuando sin efectos.")
            # Si falla, retornar el clip original sin modificar
        
        return clip
    
    def create_dynamic_image_clip(
        self,
        image_path: str,
        duration: float,
        target_width: int = 1080,
        target_height: int = 1920,
        zoom_effect: str = "in"
    ) -> VideoFileClip:
        """
        Crea un clip de video animado desde una imagen est√°tica usando efecto Ken Burns.
        
        Efectos aplicados:
        - Zoom In/Out: Recorta la imagen progresivamente (100% -> 110% o viceversa)
        - Pan: Si la imagen es horizontal, la mueve lentamente de izquierda a derecha
        
        Args:
            image_path: Ruta a la imagen (jpg, png)
            duration: Duraci√≥n del clip en segundos
            target_width: Ancho objetivo del video
            target_height: Alto objetivo del video
            zoom_effect: "in" (zoom hacia adentro) o "out" (zoom hacia afuera)
        
        Returns:
            VideoClip animado que parece video real
        """
        logger.info(f"üé¨ Creando clip animado desde imagen: {Path(image_path).name} (duraci√≥n: {duration:.2f}s)")
        
        try:
            # Cargar la imagen
            base_clip = ImageClip(image_path, duration=duration)
            img_width, img_height = base_clip.size
            
            logger.debug(f"üìê Tama√±o original de imagen: {img_width}x{img_height}")
            
            # Calcular relaci√≥n de aspecto
            img_aspect = img_width / img_height
            target_aspect = target_width / target_height
            
            # Redimensionar imagen para que cubra el canvas completo (puede recortarse)
            # Usar el lado m√°s largo para asegurar cobertura completa
            if img_aspect > target_aspect:
                # Imagen m√°s ancha: ajustar por altura
                scale_factor = target_height / img_height
                new_width = int(img_width * scale_factor)
                new_height = target_height
            else:
                # Imagen m√°s alta: ajustar por ancho
                scale_factor = target_width / img_width
                new_width = target_width
                new_height = int(img_height * scale_factor)
            
            # Redimensionar imagen base
            base_clip = base_clip.resize((new_width, new_height))
            
            # Calcular zoom (110% = 1.1x para zoom in, 0.9x para zoom out)
            zoom_start = 1.0
            zoom_end = 1.1 if zoom_effect == "in" else 0.9
            
            # Determinar si aplicar pan (solo si la imagen es significativamente horizontal)
            pan_enabled = img_aspect > 1.3
            
            # Importar funciones matem√°ticas
            from math import cos, pi
            
            # Funci√≥n de zoom progresivo
            def zoom_func(t):
                """Calcula el factor de zoom en el tiempo t."""
                progress = t / duration
                # Interpolaci√≥n suave (ease-in-out)
                smooth_progress = 0.5 * (1 - cos(pi * progress))
                return zoom_start + (zoom_end - zoom_start) * smooth_progress
            
            # Aplicar zoom usando resize con funci√≥n de tiempo
            zoomed_clip = base_clip.resize(lambda t: zoom_func(t))
            
            # Aplicar pan si es necesario
            if pan_enabled:
                # Calcular rango de movimiento horizontal
                max_width = int(new_width * zoom_end)
                pan_range = max(0, max_width - target_width)
                
                def pan_func(t):
                    """Calcula la posici√≥n X para el pan."""
                    progress = t / duration
                    smooth_progress = 0.5 * (1 - cos(pi * progress))
                    x_pos = pan_range * smooth_progress
                    return x_pos
                
                # Aplicar pan moviendo el clip
                final_clip = zoomed_clip.set_position(lambda t: (pan_func(t), 'center'))
            else:
                # Sin pan, solo centrar
                final_clip = zoomed_clip.set_position('center')
            
            # Recortar al tama√±o objetivo
            final_clip = final_clip.crop(
                x_center=final_clip.w / 2,
                y_center=final_clip.h / 2,
                width=target_width,
                height=target_height
            )
            
            # Asegurar tama√±o exacto y FPS
            final_clip = final_clip.resize((target_width, target_height))
            final_clip = final_clip.set_duration(duration)
            final_clip = final_clip.set_fps(30)
            
            logger.success(f"‚úÖ Clip animado creado: {duration:.2f}s con efecto Ken Burns (zoom: {zoom_effect}, pan: {'‚úÖ' if pan_enabled else '‚ùå'})")
            
            return final_clip
            
        except Exception as e:
            logger.error(f"‚ùå Error creando clip animado desde imagen: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            # Fallback: crear clip simple sin animaci√≥n
            try:
                simple_clip = ImageClip(image_path, duration=duration)
                simple_clip = self._resize_to_format(simple_clip, target_width, target_height)
                simple_clip = simple_clip.set_fps(30)
                logger.warning("‚ö†Ô∏è Usando clip simple sin animaci√≥n como fallback")
                return simple_clip
            except Exception as e2:
                logger.error(f"‚ùå Error en fallback: {e2}")
                raise
    
    def create_emergency_image(
        self,
        text: str,
        target_width: int = 1080,
        target_height: int = 1920,
        background_color: str = "#1a1a1a",
        output_dir: str = "assets/temp"
    ) -> Optional[str]:
        """
        Crea una imagen de emergencia cuando todos los m√©todos de obtenci√≥n de visuales fallan.
        Genera una imagen con fondo de color s√≥lido y texto opcional.
        Esta imagen luego se puede usar con create_dynamic_image_clip para crear un video.
        
        Args:
            text: Texto a mostrar en la imagen (opcional, puede ser vac√≠o)
            target_width: Ancho objetivo del video
            target_height: Alto objetivo del video
            background_color: Color de fondo en formato hexadecimal (ej: "#1a1a1a")
            output_dir: Directorio donde guardar la imagen
        
        Returns:
            Ruta del archivo de imagen creado, o None si falla
        """
        logger.warning(f"üö® Creando imagen de emergencia...")
        
        try:
            # Crear imagen de fondo usando PIL
            from PIL import Image, ImageDraw, ImageFont
            
            # Crear imagen con color de fondo
            bg_image = Image.new('RGB', (target_width, target_height), background_color)
            
            # Si hay texto, agregarlo a la imagen
            if text and text.strip():
                try:
                    draw = ImageDraw.Draw(bg_image)
                    # Intentar usar fuente del sistema, fallback a default
                    try:
                        font_size = min(80, target_width // 15)
                        # Intentar diferentes fuentes comunes
                        font_paths = [
                            "C:/Windows/Fonts/arial.ttf",
                            "C:/Windows/Fonts/arialbd.ttf",
                            "C:/Windows/Fonts/Arial.ttf",
                            "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
                        ]
                        font = None
                        for font_path in font_paths:
                            try:
                                if Path(font_path).exists():
                                    font = ImageFont.truetype(font_path, font_size)
                                    break
                            except:
                                continue
                        if font is None:
                            font = ImageFont.load_default()
                    except:
                        font = ImageFont.load_default()
                    
                    # Preparar texto (limitar longitud y dividir en l√≠neas si es necesario)
                    display_text = text.strip()[:150]
                    
                    # Calcular posici√≥n centrada
                    # Intentar obtener bbox
                    try:
                        bbox = draw.textbbox((0, 0), display_text, font=font)
                        text_width = bbox[2] - bbox[0]
                        text_height = bbox[3] - bbox[1]
                    except:
                        # Fallback si textbbox no funciona
                        text_width = len(display_text) * (font_size // 2)
                        text_height = font_size
                    
                    x = (target_width - text_width) // 2
                    y = (target_height - text_height) // 2
                    
                    # Dibujar texto con sombra para mejor legibilidad
                    shadow_offset = 3
                    draw.text((x + shadow_offset, y + shadow_offset), display_text, 
                             font=font, fill="#000000", align="center")
                    draw.text((x, y), display_text, 
                             font=font, fill="#FFFFFF", align="center")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è No se pudo agregar texto a la imagen de emergencia: {e}")
            
            # Guardar imagen
            output_path_obj = Path(output_dir)
            output_path_obj.mkdir(parents=True, exist_ok=True)
            timestamp = int(time.time())
            output_file = output_path_obj / f"emergency_{timestamp}_{hash(text) % 10000}.png"
            bg_image.save(output_file)
            
            logger.success(f"‚úÖ Imagen de emergencia creada: {output_file.name}")
            return str(output_file)
            
        except Exception as e:
            logger.error(f"‚ùå Error creando imagen de emergencia: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            
            # Fallback absoluto: crear imagen simple sin texto
            try:
                from PIL import Image
                bg_image = Image.new('RGB', (target_width, target_height), background_color)
                output_path_obj = Path(output_dir)
                output_path_obj.mkdir(parents=True, exist_ok=True)
                output_file = output_path_obj / f"emergency_fallback_{int(time.time())}.png"
                bg_image.save(output_file)
                logger.warning(f"‚ö†Ô∏è Usando imagen de emergencia simplificada (solo fondo): {output_file.name}")
                return str(output_file)
            except Exception as e2:
                logger.error(f"‚ùå Error cr√≠tico en fallback de emergencia: {e2}")
                return None
    
    def create_emergency_clip(
        self,
        text: str,
        duration: float,
        target_width: int = 1080,
        target_height: int = 1920,
        background_color: str = "#1a1a1a"
    ) -> Optional[VideoFileClip]:
        """
        Crea un clip de emergencia usando MoviePy directamente (ColorClip + TextClip).
        Esta funci√≥n NO depende de archivos externos, por lo que es m√°s robusta.
        
        Args:
            text: Texto a mostrar en el clip
            duration: Duraci√≥n del clip en segundos
            target_width: Ancho del video
            target_height: Alto del video
            background_color: Color de fondo en formato hexadecimal (ej: "#1a1a1a")
        
        Returns:
            VideoFileClip con fondo de color y texto, o None si falla
        """
        logger.warning(f"üö® Creando clip de emergencia con MoviePy (duraci√≥n: {duration}s)...")
        
        try:
            # Convertir color hexadecimal a RGB
            bg_color_hex = background_color.lstrip('#')
            bg_color_rgb = tuple(int(bg_color_hex[i:i+2], 16) for i in (0, 2, 4))
            
            # Crear ColorClip como fondo
            color_clip = ColorClip(
                size=(target_width, target_height),
                color=bg_color_rgb,
                duration=duration
            )
            
            # Intentar agregar texto si est√° disponible y el texto no est√° vac√≠o
            if text and text.strip() and self.imagemagick_configured:
                try:
                    # Preparar texto (limitar longitud)
                    display_text = text.strip()[:100]  # Limitar a 100 caracteres
                    
                    # Calcular tama√±o de fuente apropiado
                    fontsize = min(80, target_width // 15)
                    
                    # Crear TextClip
                    text_clip = TextClip(
                        display_text,
                        fontsize=fontsize,
                        color='white',
                        font=self.font if hasattr(self, 'font') else 'Arial-Bold',
                        stroke_color='black',
                        stroke_width=2,
                        method='caption',
                        size=(target_width * 0.9, None),  # 90% del ancho para m√°rgenes
                        align='center'
                    ).set_position('center').set_duration(duration)
                    
                    # Componer ColorClip + TextClip
                    final_clip = CompositeVideoClip([color_clip, text_clip])
                    logger.success(f"‚úÖ Clip de emergencia creado con texto: '{display_text[:50]}...'")
                    return final_clip
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è No se pudo agregar texto al clip de emergencia: {e}")
                    logger.info("üí° Usando solo ColorClip sin texto...")
                    # Si falla el texto, retornar solo el ColorClip
                    return color_clip
            else:
                # Si no hay texto o ImageMagick no est√° configurado, retornar solo ColorClip
                if not text or not text.strip():
                    logger.info("üí° Texto vac√≠o, usando solo ColorClip...")
                else:
                    logger.warning("‚ö†Ô∏è ImageMagick no configurado, usando solo ColorClip sin texto...")
                return color_clip
                
        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico creando clip de emergencia: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            
            # √öltimo recurso: intentar crear un ColorClip m√≠nimo
            try:
                logger.warning("üîÑ Intentando crear ColorClip m√≠nimo como √∫ltimo recurso...")
                bg_color_hex = background_color.lstrip('#')
                bg_color_rgb = tuple(int(bg_color_hex[i:i+2], 16) for i in (0, 2, 4))
                minimal_clip = ColorClip(
                    size=(target_width, target_height),
                    color=bg_color_rgb,
                    duration=duration
                )
                logger.success("‚úÖ Clip de emergencia m√≠nimo creado (solo fondo)")
                return minimal_clip
            except Exception as e2:
                logger.error(f"‚ùå ERROR CR√çTICO: No se pudo crear clip de emergencia ni siquiera m√≠nimo: {e2}")
                return None
    
    def _get_word_timestamps(self, audio_file: str) -> List[Dict[str, Any]]:
        """
        Obtiene los timestamps de palabras usando Whisper.
        Versi√≥n robusta que maneja errores de FFmpeg y rutas de OneDrive.
        
        Args:
            audio_file: Ruta del archivo de audio (relativa o absoluta)
        
        Returns:
            Lista de diccionarios con 'word', 'start', 'end' para cada palabra
        """
        # Verificar si Whisper est√° disponible
        if not self.whisper_model:
            logger.warning("‚ö†Ô∏è Whisper no disponible (FFmpeg no encontrado). Saltando subt√≠tulos.")
            return []
        
        # Verificar FFmpeg antes de intentar transcribir
        if not self.ffmpeg_available:
            logger.warning("‚ö†Ô∏è FFmpeg no encontrado en PATH. Saltando subt√≠tulos.")
            return []
        
        try:
            # Obtener la ruta base del proyecto autom√°ticamente
            BASE_DIR = Path(__file__).parent.parent.resolve()
            
            # Construir la ruta absoluta de forma segura y sanitizada
            audio_path = Path(audio_file)
            
            # Si es relativo, construir la ruta completa
            if not audio_path.is_absolute():
                audio_path = BASE_DIR / "assets" / "temp" / audio_path.name
            else:
                # Ya es absoluta, normalizar y sanitizar
                audio_path = audio_path.resolve()
            
            ruta_audio_abs = os.path.abspath(str(audio_path))
            
            logger.debug(f"Ruta absoluta generada: {ruta_audio_abs}")
            logger.info(f"Transcribiendo audio con Whisper: {Path(ruta_audio_abs).name}")
            
            # ESPERAR A QUE EL ARCHIVO EXISTA Y TENGA CONTENIDO
            if not esperar_archivo(ruta_audio_abs, intentos=30, espera=0.5):
                logger.error(f"Archivo de audio no encontrado despu√©s de esperar: {ruta_audio_abs}")
                return []
            
            # Verificaci√≥n final antes de procesar
            if not Path(ruta_audio_abs).exists():
                logger.error(f"Archivo desapareci√≥ despu√©s de esperar: {ruta_audio_abs}")
                return []
            
            # SOLUCI√ìN 2: Usar tempfile para crear archivo fuera de OneDrive
            # Crear un directorio temporal seguro fuera de OneDrive
            temp_dir_safe = Path(tempfile.gettempdir()) / "autoviral_whisper"
            temp_dir_safe.mkdir(parents=True, exist_ok=True)
            
            # Crear una copia temporal del archivo para Whisper (fuera de OneDrive)
            temp_audio_path = temp_dir_safe / f"whisper_temp_{Path(ruta_audio_abs).name}"
            
            # Limpiar archivos temporales antiguos (m√°s de 1 hora)
            try:
                for old_file in temp_dir_safe.glob("whisper_temp_*"):
                    if old_file.stat().st_mtime < (time.time() - 3600):
                        old_file.unlink()
            except Exception:
                pass
            
            try:
                logger.debug(f"Copiando archivo para Whisper (fuera de OneDrive): {temp_audio_path.name}")
                
                # Copiar el archivo a la ubicaci√≥n temporal segura
                shutil.copy2(ruta_audio_abs, temp_audio_path)
                
                # Esperar un momento adicional para asegurar que la copia est√© lista
                time.sleep(0.3)
                
                # Sanitizar ruta para Whisper (ruta absoluta)
                whisper_path = os.path.abspath(str(temp_audio_path))
                
                logger.info(f"Transcribiendo con Whisper desde copia temporal segura...")
                
                # Transcribir con Whisper usando la copia temporal
                result = self.whisper_model.transcribe(
                    whisper_path,
                    word_timestamps=True,
                    language="es"
                )
                
                logger.success(f"‚úÖ Transcripci√≥n completada para: {Path(ruta_audio_abs).name}")
                
            except FileNotFoundError as e:
                # SOLUCI√ìN 1: Capturar espec√≠ficamente el error de FFmpeg
                logger.warning(f"‚ö†Ô∏è FFmpeg no encontrado en PATH, saltando subt√≠tulos.")
                logger.warning(f"üí° Error: {e}")
                logger.warning(f"üí° Instala FFmpeg: choco install ffmpeg o desde gyan.dev")
                return []
            finally:
                # Limpiar el archivo temporal despu√©s de la transcripci√≥n
                try:
                    if temp_audio_path.exists():
                        time.sleep(0.5)  # Dar tiempo a Whisper para liberar el archivo
                        temp_audio_path.unlink()
                        logger.debug(f"Archivo temporal eliminado: {temp_audio_path.name}")
                except Exception as cleanup_error:
                    logger.warning(f"No se pudo eliminar archivo temporal: {cleanup_error}")
            
            # Procesar las palabras y sus timestamps
            words = []
            if result and "segments" in result:
                for segment in result["segments"]:
                    if "words" in segment:
                        for word_info in segment["words"]:
                            words.append({
                                "word": word_info["word"].strip(),
                                "start": word_info["start"],
                                "end": word_info["end"]
                            })
            
            logger.debug(f"Se extrajeron {len(words)} palabras con timestamps")
            return words
            
        except FileNotFoundError as e:
            # SOLUCI√ìN 1: Capturar espec√≠ficamente errores de archivos no encontrados
            logger.warning(f"‚ö†Ô∏è FFmpeg no encontrado o archivo no accesible. Saltando subt√≠tulos.")
            logger.debug(f"Error: {e}")
            return []
        except Exception as e:
            logger.error(f"Error en transcripci√≥n Whisper: {e}")
            logger.error(f"Ruta intentada: {ruta_audio_abs if 'ruta_audio_abs' in locals() else audio_file}")
            logger.warning("Continuando sin subt√≠tulos...")
            return []
    
    def create_subtitles(self, audio_file: str, audio_duration: float) -> List[TextClip]:
        """
        Crea clips de subt√≠tulos basados en la transcripci√≥n de Whisper.
        
        Args:
            audio_file: Ruta del archivo de audio
            audio_duration: Duraci√≥n del audio en segundos
        
        Returns:
            Lista de clips de texto (subt√≠tulos)
        """
        try:
            # Obtener timestamps de palabras
            words = self._get_word_timestamps(audio_file)
            
            if not words:
                logger.warning("No se pudieron generar subt√≠tulos")
                return []
            
            subtitle_clips = []
            current_text = ""
            current_start = 0.0
            max_words_per_line = 4
            
            # Agrupar palabras en l√≠neas de subt√≠tulos
            for i, word_info in enumerate(words):
                word = word_info["word"]
                start = word_info["start"]
                end = word_info["end"]
                
                if i == 0:
                    current_start = start
                    current_text = word
                elif len(current_text.split()) < max_words_per_line:
                    current_text += " " + word
                else:
                    # Crear subt√≠tulo con el texto acumulado (Estilo Viral mejorado)
                    if current_text:
                        try:
                            subtitle = TextClip(
                                current_text,
                                fontsize=70,  # Tama√±o aumentado para mejor legibilidad
                                color='white',  # Color base: blanco
                                font=self.font,  # Usar fuente personalizada si est√° disponible
                                stroke_color='black',  # Borde negro para contraste
                                stroke_width=3,  # Borde grueso para m√°ximo contraste (estilo viral profesional)
                                method='caption',
                                size=(None, None),
                                align='center'
                            ).set_position(('center', 'bottom')).set_start(current_start).set_duration(end - current_start)
                            
                            # VERIFICAR que el clip no sea None antes de agregarlo
                            if subtitle is not None:
                                subtitle_clips.append(subtitle)
                            else:
                                logger.warning(f"TextClip retorn√≥ None para texto: {current_text[:50]}...")
                        except Exception as e:
                            logger.warning(f"Error creando subt√≠tulo: {e}")
                            # Continuar sin agregar este subt√≠tulo
            
                    # Iniciar nueva l√≠nea
                    current_text = word
                    current_start = start
            
            # Agregar el √∫ltimo subt√≠tulo
            if current_text and words:
                try:
                    last_end = words[-1]["end"]
                    subtitle = TextClip(
                        current_text,
                        fontsize=60,
                        color='white',
                        font=self.font,
                        stroke_color='black',
                        stroke_width=2,
                        method='caption',
                        size=(None, None),
                        align='center'
                    ).set_position(('center', 'bottom')).set_start(current_start).set_duration(last_end - current_start)
                    
                    # VERIFICAR que el clip no sea None antes de agregarlo
                    if subtitle is not None:
                        subtitle_clips.append(subtitle)
                    else:
                        logger.warning(f"TextClip retorn√≥ None para √∫ltimo texto: {current_text[:50]}...")
                except Exception as e:
                    logger.warning(f"Error creando √∫ltimo subt√≠tulo: {e}")
            
            # Filtrar cualquier None que pueda haber quedado (defensa adicional)
            subtitle_clips = [clip for clip in subtitle_clips if clip is not None]
            
            if subtitle_clips:
                logger.success(f"‚úÖ Se crearon {len(subtitle_clips)} clips de subt√≠tulos v√°lidos")
            else:
                logger.warning("‚ö†Ô∏è No se crearon clips de subt√≠tulos v√°lidos")
            
            return subtitle_clips
            
        except Exception as e:
            logger.error(f"Error creando subt√≠tulos: {e}")
            return []
    
    def generate_karaoke_subtitles(self, audio_file: str, video_size: tuple = (1080, 1920), highlight_color: str = '#00ff00') -> List[TextClip]:
        """
        Genera subt√≠tulos estilo karaoke con word-level highlighting (Estilo Viral).
        Cada palabra se ilumina cuando se est√° diciendo con colores vibrantes y bordes gruesos.
        
        Args:
            audio_file: Ruta del archivo de audio
            video_size: Tama√±o del video (width, height)
            highlight_color: Color de la palabra activa (default: #00ff00 - Verde Ne√≥n o 'yellow')
        
        Returns:
            Lista de clips de texto (una por palabra)
        """
        try:
            # Obtener timestamps de palabras
            logger.info(f"Obteniendo timestamps de palabras para subt√≠tulos karaoke estilo viral...")
            words = self._get_word_timestamps(audio_file)
            
            if not words:
                logger.warning("‚ö†Ô∏è No se pudieron obtener timestamps de palabras. Whisper puede no estar disponible o el audio no es v√°lido.")
                logger.info("üí° Intentando continuar sin subt√≠tulos karaoke...")
                return []
            
            logger.info(f"‚úÖ Se obtuvieron {len(words)} palabras con timestamps para subt√≠tulos karaoke")
            
            width, height = video_size
            subtitle_clips = []
            
            # ============================================================
            # ESTILO VIRAL: Fuentes grandes, bordes gruesos, colores vibrantes
            # ============================================================
            base_fontsize = 70  # Aumentado para mejor legibilidad
            highlight_fontsize = int(base_fontsize * 1.3)  # 30% m√°s grande para palabras activas
            base_color = 'white'  # Color base: blanco
            stroke_color = 'black'  # Borde negro para contraste
            stroke_width = 3  # Borde grueso para m√°ximo contraste (estilo viral profesional)
            
            # Color vibrante para palabra activa: 'yellow' o '#00ff00' (Verde Ne√≥n)
            if highlight_color and highlight_color.lower() in ['yellow', '#00ff00', '#ffd700', '#ffff00']:
                highlight_color_final = highlight_color if highlight_color.startswith('#') else 'yellow'
            else:
                highlight_color_final = '#00ff00'  # Verde Ne√≥n por defecto (m√°s impactante)
            
            # Posici√≥n: centro-abajo (aproximadamente 85% desde arriba)
            y_position = int(height * 0.85)
            
            # Crear un clip de texto temporal para medir anchos (usando fuente personalizada)
            try:
                test_clip = TextClip("M", fontsize=base_fontsize, font=self.font)
                char_width_approx = test_clip.w / len("M") if hasattr(test_clip, 'w') and test_clip.w else base_fontsize * 0.6
                test_clip.close()
            except:
                char_width_approx = base_fontsize * 0.6
            
            # Agrupar palabras en l√≠neas para mostrar contexto
            # Mostrar 3-5 palabras a la vez, destacando la actual
            words_per_line = 5
            current_line_words = []
            
            for i, word_info in enumerate(words):
                word = word_info["word"].strip()
                start = word_info["start"]
                end = word_info["end"]
                duration = end - start
                
                # Agregar palabra a la l√≠nea actual
                current_line_words.append({
                    "word": word,
                    "start": start,
                    "end": end,
                    "index": i
                })
                
                # Si tenemos suficientes palabras o es la √∫ltima, crear la l√≠nea
                if len(current_line_words) >= words_per_line or i == len(words) - 1:
                    # Crear clips para cada palabra en la l√≠nea
                    # Calcular el ancho total de la l√≠nea
                    line_text = " ".join([w["word"] for w in current_line_words])
                    line_width_approx = sum(len(w["word"]) + 1 for w in current_line_words) * char_width_approx
                    
                    # Posici√≥n X inicial (centrado)
                    x_start = (width / 2) - (line_width_approx / 2)
                    current_x = x_start
                    
                    for j, w_info in enumerate(current_line_words):
                        w = w_info["word"]
                        w_start = w_info["start"]
                        w_end = w_info["end"]
                        w_duration = w_end - w_start
                        
                        # Determinar si esta palabra est√° activa (la √∫ltima de la l√≠nea)
                        is_active = (j == len(current_line_words) - 1)
                        
                        # Estilo seg√∫n si est√° activa (Estilo Viral: colores vibrantes)
                        if is_active:
                            fontsize = highlight_fontsize
                            color = highlight_color_final  # Yellow o Verde Ne√≥n para palabra activa
                            current_stroke_width = stroke_width  # Mantener stroke_width=3 para palabra activa
                        else:
                            fontsize = base_fontsize
                            color = base_color  # Blanco para palabras no activas
                            current_stroke_width = stroke_width  # Stroke_width=3 para todas las palabras
                        
                        # Calcular posici√≥n X (aproximada basada en ancho de caracteres)
                        word_width_approx = len(w) * char_width_approx
                        x_position = current_x + (word_width_approx / 2)
                        
                        try:
                            # Crear clip de texto para esta palabra (Estilo Hormozi: m√°ximo impacto visual)
                            word_clip = TextClip(
                                w,
                                fontsize=fontsize,
                                color=color,
                                font=self.font,  # Usar fuente personalizada si est√° disponible
                                stroke_color=stroke_color,
                                stroke_width=current_stroke_width,  # Borde grueso para contraste
                                method='caption',
                                size=(None, None),
                                align='center'
                            ).set_position((x_position, y_position), relative=False).set_start(w_start).set_duration(w_duration)
                            
                            if word_clip is not None:
                                subtitle_clips.append(word_clip)
                        except Exception as e:
                            logger.warning(f"Error creando clip de palabra '{w}': {e}")
                            # Continuar sin esta palabra
                        
                        # Actualizar posici√≥n X para la siguiente palabra
                        current_x += word_width_approx + char_width_approx  # +1 espacio
                    
                    # Limpiar l√≠nea actual
                    current_line_words = []
            
            # Filtrar None
            subtitle_clips = [clip for clip in subtitle_clips if clip is not None]
            
            if subtitle_clips:
                logger.success(f"‚úÖ Se crearon {len(subtitle_clips)} clips de subt√≠tulos karaoke")
            else:
                logger.warning("‚ö†Ô∏è No se crearon clips de subt√≠tulos karaoke v√°lidos")
            
            return subtitle_clips
            
        except Exception as e:
            logger.error(f"Error creando subt√≠tulos karaoke: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def create_static_subtitle(self, text: str, duration: float, video_size: tuple = (1080, 1920), position: str = "bottom") -> Optional[TextClip]:
        """
        Crea un subt√≠tulo est√°tico desde texto plano.
        Fallback cuando el karaoke no funciona o no hay audio para transcribir.
        
        Args:
            text: Texto a mostrar
            duration: Duraci√≥n del subt√≠tulo en segundos
            video_size: Tama√±o del video (width, height)
            position: Posici√≥n del subt√≠tulo ("bottom", "center", "top")
        
        Returns:
            TextClip o None si falla
        """
        try:
            width, height = video_size
            
            # ============================================================
            # ESTILO VIRAL: Fuentes grandes, bordes gruesos, m√°ximo contraste
            # ============================================================
            fontsize = 70  # Aumentado para mejor legibilidad
            color = 'white'  # Color base: blanco
            stroke_color = 'black'  # Borde negro para contraste
            stroke_width = 3  # Borde grueso para m√°ximo contraste (estilo viral profesional)
            
            # Posici√≥n Y seg√∫n el par√°metro
            if position == "bottom":
                y_position = int(height * 0.85)  # 85% desde arriba
            elif position == "center":
                y_position = int(height * 0.5)  # Centro
            else:
                y_position = int(height * 0.15)  # 15% desde arriba
            
            # Limitar texto a un ancho razonable (aproximadamente 80% del ancho)
            max_width = int(width * 0.8)
            
            logger.info(f"Creando subt√≠tulo est√°tico estilo viral: '{text[:50]}...' (duraci√≥n: {duration:.2f}s)")
            
            try:
                subtitle_clip = TextClip(
                    text,
                    fontsize=fontsize,
                    color=color,
                    font=self.font,  # Usar fuente personalizada si est√° disponible
                    stroke_color=stroke_color,
                    stroke_width=stroke_width,  # Borde grueso para m√°ximo contraste
                    method='caption',
                    size=(max_width, None),
                    align='center'
                ).set_position(('center', y_position), relative=False).set_start(0).set_duration(duration)
                
                if subtitle_clip is not None:
                    logger.success("‚úÖ Subt√≠tulo est√°tico creado exitosamente")
                    return subtitle_clip
                else:
                    logger.warning("‚ö†Ô∏è TextClip retorn√≥ None para subt√≠tulo est√°tico")
                    return None
                    
            except Exception as e:
                logger.error(f"Error creando TextClip para subt√≠tulo est√°tico: {e}")
                logger.warning("üí° Aseg√∫rate de que ImageMagick est√© instalado y configurado")
                return None
                
        except Exception as e:
            logger.error(f"Error en create_static_subtitle: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None
    
    def process_scene(self, scene: Dict, idx: int, background_music: Optional[str] = None, music_volume: float = 0.1, use_karaoke: bool = True, target_width: int = None, target_height: int = None, use_subtitles: bool = True, enable_color_grading: bool = False, style_code: Optional[str] = None, style_label: Optional[str] = None) -> Optional[VideoFileClip]:
        """
        Procesa una escena individual combinando video, audio y subt√≠tulos.
        Retorna None si hay un error para evitar crashes.
        
        Args:
            scene: Diccionario con 'text', 'visual_query', 'duration_estimate'
            idx: √çndice de la escena (0-based)
            background_music: Ruta opcional a m√∫sica de fondo
            music_volume: Volumen de la m√∫sica de fondo (0.0 a 1.0)
            use_karaoke: Si True, usa subt√≠tulos karaoke. Si False, usa subt√≠tulos est√°ticos
            target_width: Ancho objetivo del video
            target_height: Alto objetivo del video
            use_subtitles: Si True, incrusta subt√≠tulos. Si False, renderiza Clean Feed (sin texto)
            enable_color_grading: Si True, aplica color grading al video
            style_code: C√≥digo/nombre interno del estilo (ej: "HORROR")
            style_label: Etiqueta amigable del estilo (ej: "üíÄ Horror / Creepypasta")
        
        Returns:
            Clip de video procesado o None si hay error
        """
        logger.info(f"Procesando escena {idx + 1}...")
        
        # Obtener la ruta base del proyecto
        BASE_DIR = Path(__file__).parent.parent.resolve()
        
        # Construir rutas absolutas y sanitizadas
        audio_file = os.path.abspath(str(BASE_DIR / "assets" / "temp" / f"audio_{idx}.mp3"))
        video_file = os.path.abspath(str(BASE_DIR / "assets" / "temp" / f"scene_{idx:02d}_video.mp4"))
        
        # Verificar que los archivos existen
        if not Path(audio_file).exists():
            logger.error(f"Archivo de audio no encontrado: {audio_file}")
            logger.warning(f"‚ö†Ô∏è Saltando escena {idx + 1} por falta de audio")
            return None
        
        # Verificar si existe video o imagen
        video_path = Path(video_file)
        image_extensions = ['.jpg', '.jpeg', '.png', '.webp']
        is_image = False
        
        if not video_path.exists():
            # Buscar si hay una imagen con el mismo nombre base
            for ext in image_extensions:
                image_file = video_path.with_suffix(ext)
                if image_file.exists():
                    video_file = str(image_file)
                    is_image = True
                    logger.info(f"üì∏ Imagen encontrada en lugar de video: {image_file.name}")
                    break
            
            if not is_image:
                logger.error(f"Archivo de video/imagen no encontrado: {video_file}")
                logger.warning(f"‚ö†Ô∏è Saltando escena {idx + 1} por falta de recurso visual")
                return None
        
        original_video_clip = None
        original_audio_clip = None
        
        try:
            # Crear subt√≠tulos ANTES de cargar el audio con MoviePy
            temp_audio_clip = AudioFileClip(audio_file)
            audio_duration = temp_audio_clip.duration
            temp_audio_clip.close()
            
            # Generar subt√≠tulos SOLO si use_subtitles est√° activado
            subtitle_clips_list = []
            
            if use_subtitles:
                # Generar subt√≠tulos (puede retornar lista vac√≠a o lista con clips v√°lidos)
                # Usar dimensiones din√°micas si se proporcionan
                video_size = (target_width or TARGET_WIDTH, target_height or TARGET_HEIGHT)
                
                if use_karaoke:
                    logger.info(f"Generando subt√≠tulos karaoke para escena {idx + 1}...")
                    subtitle_clips_list = self.generate_karaoke_subtitles(audio_file, video_size=video_size)
                    logger.info(f"Subt√≠tulos karaoke generados: {len(subtitle_clips_list)} clips")
                else:
                    logger.info(f"Generando subt√≠tulos est√°ticos para escena {idx + 1}...")
                    subtitle_clips_list = self.create_subtitles(audio_file, audio_duration)
                    logger.info(f"Subt√≠tulos est√°ticos generados: {len(subtitle_clips_list)} clips")
                
                # FILTRAR cualquier None de la lista de subt√≠tulos
                subtitle_clips_list = [clip for clip in subtitle_clips_list if clip is not None]
                
                # FALLBACK: Si no se generaron subt√≠tulos karaoke, intentar con subt√≠tulos est√°ticos desde el texto
                if not subtitle_clips_list and use_karaoke:
                    logger.warning(f"‚ö†Ô∏è No se generaron subt√≠tulos karaoke para escena {idx + 1}, intentando fallback est√°tico...")
                    scene_text = scene.get("text", "")
                    if scene_text and scene_text.strip():
                        try:
                            static_subtitle = self.create_static_subtitle(
                                text=scene_text.strip(),
                                duration=audio_duration,
                                video_size=video_size,
                                position="bottom"
                            )
                            if static_subtitle:
                                subtitle_clips_list = [static_subtitle]
                                logger.success(f"‚úÖ Subt√≠tulo est√°tico creado como fallback para escena {idx + 1}")
                            else:
                                logger.warning(f"‚ö†Ô∏è Fallback est√°tico tambi√©n fall√≥ para escena {idx + 1}")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Error en fallback est√°tico para escena {idx + 1}: {e}")
                
                logger.info(f"Total de clips de subt√≠tulos v√°lidos para escena {idx + 1}: {len(subtitle_clips_list)}")
            else:
                logger.info(f"üìù Saltando generaci√≥n de subt√≠tulos para escena {idx + 1} (Clean Feed activado)")
            
            # Cargar video/audio (o crear clip animado desde imagen)
            if is_image:
                # Crear clip animado desde imagen con efecto Ken Burns
                logger.info(f"üé¨ Animando imagen con efecto Ken Burns para escena {idx + 1}...")
                try:
                    original_video_clip = self.create_dynamic_image_clip(
                        image_path=video_file,
                        duration=audio_duration,
                        target_width=final_width,
                        target_height=final_height,
                        zoom_effect="in"  # Zoom in por defecto
                    )
                    if original_video_clip is None:
                        logger.error(f"‚ùå create_dynamic_image_clip retorn√≥ None para escena {idx + 1}")
                        return None
                except Exception as e:
                    logger.error(f"‚ùå Error creando clip animado para escena {idx + 1}: {e}")
                    return None
            else:
                # Cargar video normal
                try:
                    if not os.path.exists(video_file):
                        logger.error(f"‚ùå Archivo de video no existe: {video_file}")
                        return None
                    
                    original_video_clip = VideoFileClip(video_file)
                    
                    # VALIDACI√ìN CR√çTICA: Verificar que el clip se carg√≥ correctamente
                    if original_video_clip is None:
                        logger.error(f"‚ùå VideoFileClip retorn√≥ None para: {video_file}")
                        return None
                    
                    # Verificar que tiene los m√©todos necesarios
                    if not hasattr(original_video_clip, 'duration') or not hasattr(original_video_clip, 'get_frame'):
                        logger.error(f"‚ùå El clip cargado no tiene los atributos necesarios: {video_file}")
                        if original_video_clip:
                            try:
                                original_video_clip.close()
                            except:
                                pass
                        return None
                    
                    # CR√çTICO: Silenciar audio original del video de stock para evitar ruido
                    # El audio se manejar√° por separado (TTS + m√∫sica)
                    original_video_clip = original_video_clip.without_audio()
                    logger.debug(f"üîá Audio original del video de stock silenciado para escena {idx + 1}")
                except Exception as e:
                    logger.error(f"‚ùå Error cargando video para escena {idx + 1}: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())
                    return None
            
            # VALIDACI√ìN FINAL: Verificar que original_video_clip es v√°lido antes de continuar
            if original_video_clip is None:
                logger.error(f"‚ùå original_video_clip es None despu√©s de cargar para escena {idx + 1}")
                return None
            
            # Cargar audio
            try:
                original_audio_clip = AudioFileClip(audio_file)
                if original_audio_clip is None:
                    logger.error(f"‚ùå AudioFileClip retorn√≥ None para: {audio_file}")
                    if original_video_clip:
                        try:
                            original_video_clip.close()
                        except:
                            pass
                    return None
            except Exception as e:
                logger.error(f"‚ùå Error cargando audio para escena {idx + 1}: {e}")
                if original_video_clip:
                    try:
                        original_video_clip.close()
                    except:
                        pass
                return None
            
            # Ajustar duraci√≥n del video al audio
            video_duration = original_audio_clip.duration
            
            # VALIDACI√ìN: Verificar duraci√≥n v√°lida antes de usar subclip
            if video_duration <= 0:
                logger.error(f"‚ùå Duraci√≥n de audio inv√°lida: {video_duration} para escena {idx + 1}")
                try:
                    original_video_clip.close()
                    original_audio_clip.close()
                except:
                    pass
                return None
            
            # Validar que el clip de video tiene duraci√≥n v√°lida
            try:
                video_clip_duration = original_video_clip.duration
                if video_clip_duration <= 0:
                    logger.error(f"‚ùå Duraci√≥n de video inv√°lida: {video_clip_duration} para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                
                # Usar la duraci√≥n m√≠nima entre video y audio
                clip_duration = min(video_duration, video_clip_duration)
                background_clip = original_video_clip.subclip(0, clip_duration)
                
                # VALIDACI√ìN POST-SUBCLIP: Verificar que subclip funcion√≥
                if background_clip is None:
                    logger.error(f"‚ùå subclip retorn√≥ None para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                    
            except Exception as e:
                logger.error(f"‚ùå Error procesando duraci√≥n/subclip para escena {idx + 1}: {e}")
                import traceback
                logger.debug(traceback.format_exc())
                try:
                    original_video_clip.close()
                    original_audio_clip.close()
                except:
                    pass
                return None
            
            # --- REDIMENSIONAR AL FORMATO OBJETIVO (din√°mico) ---
            final_width = target_width or TARGET_WIDTH
            final_height = target_height or TARGET_HEIGHT
            style_slug = self._normalize_style_slug(style_code or style_label or "general")
            
            # VALIDACI√ìN: Verificar que background_clip es v√°lido antes de redimensionar
            if background_clip is None:
                logger.error(f"‚ùå background_clip es None antes de redimensionar para escena {idx + 1}")
                try:
                    original_video_clip.close()
                    original_audio_clip.close()
                except:
                    pass
                return None
            
            try:
                background_clip = self._resize_to_format(background_clip, final_width, final_height)
                if background_clip is None:
                    logger.error(f"‚ùå _resize_to_format retorn√≥ None para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                logger.debug(f"Video redimensionado a {final_width}x{final_height} para escena {idx + 1}")
            except Exception as e:
                logger.error(f"‚ùå Error redimensionando video para escena {idx + 1}: {e}")
                try:
                    original_video_clip.close()
                    original_audio_clip.close()
                except:
                    pass
                return None
            
            # --- APLICAR COLOR GRADING (si est√° habilitado) ---
            try:
                background_clip = self._apply_color_grading(background_clip, enable_color_grading)
                if background_clip is None:
                    logger.error(f"‚ùå _apply_color_grading retorn√≥ None para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
            except Exception as e:
                logger.error(f"‚ùå Error aplicando color grading para escena {idx + 1}: {e}")
                # Continuar sin color grading en lugar de fallar completamente
                logger.warning(f"‚ö†Ô∏è Continuando sin color grading para escena {idx + 1}")
            
            # A√±adir m√∫sica de fondo si est√° disponible (con loop si es necesario)
            final_audio = original_audio_clip
            if background_music and Path(background_music).exists():
                try:
                    music_clip = AudioFileClip(background_music)
                    music_duration = music_clip.duration
                    
                    # Si la m√∫sica es m√°s corta que el video, hacer loop
                    if music_duration < video_duration:
                        loops_needed = int(video_duration / music_duration) + 1
                        music_clips = [music_clip] * loops_needed
                        music_clip = concatenate_audioclips(music_clips).subclip(0, video_duration)
                        logger.debug(f"M√∫sica looped: {music_duration:.2f}s -> {video_duration:.2f}s")
                    else:
                        # Si es m√°s larga, cortar al tama√±o del video
                        music_clip = music_clip.subclip(0, video_duration)
                    
                    music_clip = music_clip.volumex(music_volume)
                    final_audio = CompositeAudioClip([original_audio_clip, music_clip])
                except Exception as e:
                    logger.warning(f"Error a√±adiendo m√∫sica de fondo: {e}")
            
            # ============================================================
            # FIX: NO AGREGAR AUDIO AQU√ç - Se agregar√° al final como pista completa
            # ============================================================
            # El audio se manejar√° a nivel global en render_final_video
            # Solo procesamos el video visual aqu√≠
            
            # L√ìGICA DEFENSIVA: Construir layers de forma segura
            layers = [background_clip]  # Clip sin audio
            
            # VERIFICACI√ìN: Solo agregar subt√≠tulos si existen y no son None
            if subtitle_clips_list and len(subtitle_clips_list) > 0:
                # Filtrar una vez m√°s por si acaso
                valid_subtitles = [clip for clip in subtitle_clips_list if clip is not None]
                if valid_subtitles:
                    layers.extend(valid_subtitles)
                    logger.debug(f"Agregando {len(valid_subtitles)} clips de subt√≠tulos a la escena {idx + 1}")
                else:
                    logger.warning(f"‚ö†Ô∏è Renderizando escena {idx + 1} sin subt√≠tulos (todos los clips eran None)")
            else:
                logger.warning(f"‚ö†Ô∏è Renderizando escena {idx + 1} sin subt√≠tulos (no se generaron subt√≠tulos)")
            
            # Crear CompositeVideoClip solo con layers v√°lidos (nunca None)
            try:
                # VALIDACI√ìN: Verificar que background_clip es v√°lido antes de crear composite
                if background_clip is None:
                    logger.error(f"‚ùå background_clip es None antes de crear composite para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                
                if len(layers) > 1:
                    # Hay subt√≠tulos, crear composite
                    # VALIDACI√ìN CR√çTICA: Filtrar cualquier None de los layers ANTES de crear composite
                    valid_layers = []
                    for i, layer in enumerate(layers):
                        if layer is None:
                            logger.warning(f"‚ö†Ô∏è Layer {i} es None en escena {idx + 1}, filtrando...")
                            continue
                        # Verificar que tiene los atributos necesarios
                        if not hasattr(layer, 'duration') or not hasattr(layer, 'get_frame'):
                            logger.warning(f"‚ö†Ô∏è Layer {i} no tiene atributos necesarios en escena {idx + 1}, filtrando...")
                            continue
                        valid_layers.append(layer)
                    
                    if len(valid_layers) == 0:
                        logger.error(f"‚ùå Todos los layers son inv√°lidos para escena {idx + 1}")
                        try:
                            original_video_clip.close()
                            original_audio_clip.close()
                        except:
                            pass
                        return None
                    
                    if len(valid_layers) == 1:
                        # Solo hay un layer v√°lido, usarlo directamente
                        video_clip = valid_layers[0]
                    else:
                        # Crear composite solo con layers v√°lidos
                        video_clip = CompositeVideoClip(valid_layers)
                    
                    if video_clip is None:
                        logger.error(f"‚ùå CompositeVideoClip retorn√≥ None para escena {idx + 1}")
                        try:
                            original_video_clip.close()
                            original_audio_clip.close()
                        except:
                            pass
                        return None
                else:
                    # No hay subt√≠tulos, usar solo el clip de fondo
                    video_clip = background_clip
                    if video_clip is None:
                        logger.error(f"‚ùå background_clip es None para escena {idx + 1}")
                        try:
                            original_video_clip.close()
                            original_audio_clip.close()
                        except:
                            pass
                        return None
                
                # Ajustar duraci√≥n final del clip visual (sin audio)
                # La duraci√≥n se ajustar√° al audio completo en render_final_video
                video_clip = video_clip.set_duration(video_duration)
                
                # VALIDACI√ìN FINAL: Verificar que video_clip es v√°lido y tiene los m√©todos necesarios
                if video_clip is None:
                    logger.error(f"‚ùå video_clip es None despu√©s de set_duration para escena {idx + 1}")
                    try:
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                
                # Verificar que tiene los atributos necesarios
                if not hasattr(video_clip, 'duration') or not hasattr(video_clip, 'get_frame'):
                    logger.error(f"‚ùå video_clip no tiene atributos necesarios despu√©s de procesar para escena {idx + 1}")
                    try:
                        video_clip.close() if hasattr(video_clip, 'close') else None
                        original_video_clip.close()
                        original_audio_clip.close()
                    except:
                        pass
                    return None
                
                # Guardar referencia al audio original para referencia (pero no lo usamos aqu√≠)
                # El audio se manejar√° globalmente
                
                # NO cerrar los clips aqu√≠ - se cerrar√°n despu√©s de concatenar
                # Guardar referencias para poder cerrarlos despu√©s
                video_clip._original_video = original_video_clip
                video_clip._original_audio = original_audio_clip
                
                logger.success(f"‚úÖ Escena {idx + 1} procesada correctamente (duraci√≥n: {video_clip.duration:.2f}s)")
                return video_clip
                
            except Exception as e:
                logger.error(f"‚ùå Error creando composite o ajustando duraci√≥n para escena {idx + 1}: {e}")
                import traceback
                logger.debug(traceback.format_exc())
                try:
                    if 'video_clip' in locals() and video_clip:
                        video_clip.close()
                    original_video_clip.close()
                    original_audio_clip.close()
                except:
                    pass
                return None
            
        except Exception as e:
            logger.error(f"Error procesando escena {idx + 1}: {e}")
            logger.warning(f"‚ö†Ô∏è Retornando None para escena {idx + 1} para evitar crash")
            # Cerrar clips si hay error antes de retornar None
            if original_video_clip:
                try:
                    original_video_clip.close()
                except:
                    pass
            if original_audio_clip:
                try:
                    original_audio_clip.close()
                except:
                    pass
            return None
    
    def render_final_video(self, scenes: List[Dict], output_path: str, background_music: Optional[str] = None, music_volume: float = 0.1, target_width: int = None, target_height: int = None, bitrate: str = None, use_subtitles: bool = True, watermark_text: Optional[str] = None, watermark_position: str = "bottom-right", enable_color_grading: bool = False, use_crossfade_transitions: bool = False, crossfade_duration: float = 0.5, add_branding: bool = False, style_code: Optional[str] = None, style_label: Optional[str] = None, use_crossfade: bool = False, target_resolution: tuple = None) -> str:
        """
        Renderiza el video final combinando todas las escenas.
        
        Args:
            scenes: Lista de diccionarios de escenas
            output_path: Ruta de salida del video
            background_music: Ruta opcional a m√∫sica de fondo
            music_volume: Volumen de la m√∫sica de fondo
            target_width: Ancho objetivo del video (opcional, usa TARGET_WIDTH por defecto)
            target_height: Alto objetivo del video (opcional, usa TARGET_HEIGHT por defecto)
            bitrate: Bitrate para el video (opcional, se calcula autom√°ticamente seg√∫n resoluci√≥n)
            use_subtitles: Si True, incrusta subt√≠tulos. Si False, renderiza Clean Feed (sin texto)
            watermark_text: Texto de marca de agua (opcional, ej: "@MiCanal")
            watermark_position: Posici√≥n del watermark ("bottom-right", "top-center", "bottom-left", "top-right")
            add_branding: Si True, agrega intro/outro y overlay de CTA si existen en assets/branding
            style_code: C√≥digo/nombre interno del estilo (ej: "HORROR")
            style_label: Etiqueta amigable del estilo (ej: "üíÄ Horror / Creepypasta")
            use_crossfade_transitions: Si True, aplica fundidos suaves entre clips
            use_crossfade: Si True, aplica fundidos suaves entre clips (alias de use_crossfade_transitions)
            target_resolution: Tupla (width, height) con la resoluci√≥n objetivo del video (ej: (1080, 1920))
                               Si se proporciona, sobrescribe target_width y target_height
        
        Returns:
            Ruta del video renderizado
        """
        logger.info(f"Iniciando renderizado de {len(scenes)} escenas...")
        
        # Calcular style_slug desde style_code y style_label (necesario para branding)
        style_slug = self._normalize_style_slug(style_code or style_label or "general")
        
        # Obtener ruta absoluta para m√∫sica de fondo
        if background_music:
            BASE_DIR = Path(__file__).parent.parent.resolve()
            music_path = (BASE_DIR / background_music).resolve()
            if music_path.exists():
                background_music = str(music_path)
            else:
                logger.warning(f"Archivo de m√∫sica no encontrado: {music_path}")
                logger.info("Continuando sin m√∫sica de fondo...")
                background_music = None
        
        clips = []
        try:
            # Si target_resolution est√° proporcionado, extraer width y height de ah√≠
            if target_resolution and isinstance(target_resolution, (tuple, list)) and len(target_resolution) >= 2:
                target_width = target_resolution[0]
                target_height = target_resolution[1]
                logger.info(f"üìê Resoluci√≥n objetivo desde target_resolution: {target_width}x{target_height}")
            
            # Usar dimensiones din√°micas si se proporcionan, sino usar las por defecto
            final_width = target_width or TARGET_WIDTH
            final_height = target_height or TARGET_HEIGHT
            
            # Logging sobre subt√≠tulos
            if use_subtitles:
                logger.info("üìù Subt√≠tulos (Burn-in) activados - Generando subt√≠tulos para todas las escenas")
            else:
                logger.info("üìù Renderizando Clean Feed (Sin subt√≠tulos) - Saltando generaci√≥n de subt√≠tulos")
            
            # Procesar cada escena
            for idx, scene in enumerate(scenes):
                try:
                    clip = self.process_scene(scene, idx, background_music, music_volume, use_karaoke=use_subtitles, target_width=final_width, target_height=final_height, use_subtitles=use_subtitles, enable_color_grading=enable_color_grading, style_code=style_code, style_label=style_label)
                    clips.append(clip)  # Puede ser None si fall√≥
                except Exception as e:
                    logger.error(f"Error procesando escena {idx + 1}: {e}")
                    logger.warning(f"‚ö†Ô∏è Agregando None para escena {idx + 1}")
                    clips.append(None)
            
            # FILTRADO AGRESIVO: Filtrar clips None e inv√°lidos antes de concatenar
            final_clips = []
            for idx, clip in enumerate(clips):
                if clip is None:
                    logger.warning(f"‚ö†Ô∏è Clip {idx} es None, filtrando...")
                    continue
                
                # Validar que el clip tenga los atributos b√°sicos necesarios
                try:
                    if not hasattr(clip, 'duration') or not hasattr(clip, 'get_frame'):
                        logger.warning(f"‚ö†Ô∏è Clip {idx} no tiene atributos necesarios (duration/get_frame), filtrando...")
                        continue
                    
                    # Validar que la duraci√≥n sea v√°lida
                    if clip.duration <= 0:
                        logger.warning(f"‚ö†Ô∏è Clip {idx} tiene duraci√≥n inv√°lida ({clip.duration}), filtrando...")
                        continue
                    
                    final_clips.append(clip)
                    logger.debug(f"‚úÖ Clip {idx} validado (duraci√≥n: {clip.duration:.2f}s)")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error validando clip {idx}: {e}")
                    logger.warning(f"‚ö†Ô∏è Filtrando clip {idx} debido a error de validaci√≥n")
                    continue
            
            # Verificar que hay al menos un clip v√°lido
            if len(final_clips) == 0:
                raise ValueError("‚ùå ¬°No hay clips v√°lidos para renderizar! Todas las escenas fallaron o son inv√°lidas.")
            
            # Informar sobre clips filtrados
            filtered_count = len(clips) - len(final_clips)
            if filtered_count > 0:
                logger.warning(f"‚ö†Ô∏è {filtered_count} escena(s) fallaron y fueron filtradas. Renderizando con {len(final_clips)} escena(s) v√°lida(s).")
            
            # ============================================================
            # FIX CR√çTICO: CARGA DE AUDIO COMPLETO ANTES DE CONCATENAR
            # ============================================================
            logger.info("üîä Cargando pista de audio completa...")
            BASE_DIR = Path(__file__).parent.parent.resolve()
            temp_dir = BASE_DIR / "assets" / "temp"
            
            # Cargar TODOS los audios y concatenarlos en una pista completa
            full_audio_clips = []
            total_audio_duration = 0.0
            
            for idx in range(len(scenes)):
                audio_file = temp_dir / f"audio_{idx}.mp3"
                if audio_file.exists():
                    try:
                        audio_clip = AudioFileClip(str(audio_file))
                        full_audio_clips.append(audio_clip)
                        total_audio_duration += audio_clip.duration
                        logger.debug(f"Audio {idx} cargado: {audio_clip.duration:.2f}s")
                    except Exception as e:
                        logger.warning(f"Error cargando audio_{idx}.mp3: {e}")
            
            # Concatenar todos los audios en una pista completa
            if full_audio_clips:
                # VALIDACI√ìN: Filtrar cualquier None antes de concatenar
                valid_audio_clips = []
                for i, audio_clip in enumerate(full_audio_clips):
                    if audio_clip is None:
                        logger.warning(f"‚ö†Ô∏è Audio clip {i} es None, filtrando...")
                        continue
                    # Verificar que tiene duraci√≥n v√°lida
                    try:
                        if not hasattr(audio_clip, 'duration') or audio_clip.duration <= 0:
                            logger.warning(f"‚ö†Ô∏è Audio clip {i} tiene duraci√≥n inv√°lida, filtrando...")
                            continue
                        valid_audio_clips.append(audio_clip)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error validando audio clip {i}: {e}, filtrando...")
                        continue
                
                if not valid_audio_clips:
                    logger.warning("‚ö†Ô∏è No hay clips de audio v√°lidos despu√©s del filtrado. El video quedar√° sin audio.")
                    full_audio_track = None
                    total_audio_duration = 0.0
                else:
                    logger.info(f"üîä Concatenando {len(valid_audio_clips)} pistas de audio v√°lidas en pista completa...")
                    try:
                        full_audio_track = concatenate_audioclips(valid_audio_clips)
                        if full_audio_track is None:
                            logger.error("‚ùå concatenate_audioclips retorn√≥ None")
                            full_audio_track = None
                            total_audio_duration = 0.0
                        else:
                            total_audio_duration = full_audio_track.duration
                            logger.success(f"‚úÖ Pista de audio completa: {total_audio_duration:.2f}s")
                    except Exception as e:
                        logger.error(f"‚ùå Error concatenando audios: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
                        full_audio_track = None
                        total_audio_duration = 0.0
            else:
                logger.warning("‚ö†Ô∏è No se encontraron archivos de audio. El video quedar√° sin audio.")
                full_audio_track = None
                total_audio_duration = 0.0
            
            # ============================================================
            # CONCATENAR CLIPS VISUALES (SIN AUDIO)
            # ============================================================
            logger.info(f"üé¨ Concatenando {len(final_clips)} escenas v√°lidas (solo video)...")
            
            # FILTRADO AGRESIVO: Remover audio y validar clips antes de concatenar
            video_only_clips = []
            for idx, clip in enumerate(final_clips):
                if clip is None:
                    logger.warning(f"‚ö†Ô∏è Clip {idx} es None, saltando...")
                    continue
                
                try:
                    # Validar que el clip tenga los m√©todos necesarios
                    if not hasattr(clip, 'get_frame') or not hasattr(clip, 'without_audio'):
                        logger.warning(f"‚ö†Ô∏è Clip {idx} no tiene m√©todos necesarios, saltando...")
                        continue
                    
                    # Remover audio del clip individual
                    video_clip_clean = clip.without_audio()
                    
                    # Validar que el clip limpio tambi√©n sea v√°lido
                    if video_clip_clean is None:
                        logger.warning(f"‚ö†Ô∏è Clip {idx} se volvi√≥ None despu√©s de remover audio, saltando...")
                        continue
                    
                    # VALIDACI√ìN ADICIONAL: Verificar que el audio removido no dej√≥ componentes None
                    # Si el clip original ten√≠a audio problem√°tico, asegurarse de que se removi√≥ correctamente
                    if hasattr(video_clip_clean, 'audio') and video_clip_clean.audio is not None:
                        # Si todav√≠a tiene audio despu√©s de without_audio(), puede ser problem√°tico
                        audio_obj = video_clip_clean.audio
                        if hasattr(audio_obj, 'clips') and audio_obj.clips:
                            for audio_sub in audio_obj.clips:
                                if audio_sub is None or not hasattr(audio_sub, 'get_frame'):
                                    logger.warning(f"‚ö†Ô∏è Clip {idx} tiene audio inv√°lido despu√©s de without_audio(), removiendo nuevamente...")
                                    try:
                                        video_clip_clean = video_clip_clean.without_audio()
                                    except:
                                        logger.warning(f"‚ö†Ô∏è No se pudo remover audio inv√°lido del clip {idx}")
                    
                    # Validar que el clip limpio tenga duraci√≥n v√°lida
                    if not hasattr(video_clip_clean, 'duration') or video_clip_clean.duration <= 0:
                        logger.warning(f"‚ö†Ô∏è Clip {idx} tiene duraci√≥n inv√°lida, saltando...")
                        continue
                    
                    # Validar que tiene get_frame
                    if not hasattr(video_clip_clean, 'get_frame'):
                        logger.warning(f"‚ö†Ô∏è Clip {idx} no tiene get_frame despu√©s de limpiar, saltando...")
                        continue
                    
                    video_only_clips.append(video_clip_clean)
                    logger.debug(f"‚úÖ Clip {idx} validado y agregado (duraci√≥n: {video_clip_clean.duration:.2f}s)")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error validando clip {idx}: {e}")
                    logger.warning(f"‚ö†Ô∏è Saltando clip {idx} debido a error de validaci√≥n")
                    continue
            
            # Verificar que hay al menos un clip v√°lido despu√©s del filtrado agresivo
            if not video_only_clips:
                raise ValueError("‚ùå ¬°No hay clips v√°lidos para renderizar! Todas las escenas fallaron o son inv√°lidas.")
            
            logger.info(f"‚úÖ {len(video_only_clips)} clip(s) v√°lido(s) listos para concatenar (de {len(final_clips)} originales)")
            
            # Concatenar solo los clips visuales v√°lidos
            # Usar use_crossfade si est√° disponible, sino usar use_crossfade_transitions
            crossfade_enabled = (use_crossfade or use_crossfade_transitions) and len(video_only_clips) > 1
            effective_crossfade = crossfade_duration
            if crossfade_enabled:
                min_duration = min(clip.duration for clip in video_only_clips)
                if min_duration <= 0.2:
                    logger.warning("‚ö†Ô∏è Clips demasiado cortos para aplicar crossfade. Usando cortes secos.")
                    crossfade_enabled = False
                else:
                    if effective_crossfade >= min_duration:
                        effective_crossfade = max(0.1, min_duration * 0.4)
                    logger.info(f"üéûÔ∏è Transiciones suaves activadas (crossfade {effective_crossfade:.2f}s).")
                    prepared_clips = [video_only_clips[0]]
                    for clip in video_only_clips[1:]:
                        try:
                            prepared_clips.append(clip.crossfadein(effective_crossfade))
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è No se pudo aplicar crossfade a un clip: {e}. Usando versi√≥n sin transici√≥n.")
                            prepared_clips.append(clip)
                    video_only_clips = prepared_clips

            # VALIDACI√ìN FINAL CR√çTICA: Verificar que TODOS los clips son v√°lidos antes de concatenar
            # MoviePy puede llamar internamente a get_frame() durante concatenate_videoclips
            final_valid_clips = []
            for i, clip in enumerate(video_only_clips):
                if clip is None:
                    logger.warning(f"‚ö†Ô∏è Clip {i} es None antes de concatenar, filtrando...")
                    continue
                # Verificar que tiene los atributos necesarios
                if not hasattr(clip, 'duration') or not hasattr(clip, 'get_frame'):
                    logger.warning(f"‚ö†Ô∏è Clip {i} no tiene atributos necesarios antes de concatenar, filtrando...")
                    continue
                # Verificar duraci√≥n v√°lida
                try:
                    if clip.duration <= 0:
                        logger.warning(f"‚ö†Ô∏è Clip {i} tiene duraci√≥n inv√°lida ({clip.duration}), filtrando...")
                        continue
                    final_valid_clips.append(clip)
                    logger.debug(f"‚úÖ Clip {i} validado para concatenaci√≥n (duraci√≥n: {clip.duration:.2f}s)")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error validando clip {i} para concatenaci√≥n: {e}, filtrando...")
                    continue
            
            if len(final_valid_clips) == 0:
                raise ValueError("‚ùå ¬°No hay clips v√°lidos para concatenar! Todos los clips fueron filtrados.")
            
            if len(final_valid_clips) < len(video_only_clips):
                logger.warning(f"‚ö†Ô∏è Se filtraron {len(video_only_clips) - len(final_valid_clips)} clips inv√°lidos antes de concatenar")
            
            video_only_clips = final_valid_clips
            
            try:
                if crossfade_enabled:
                    final_video_clip = concatenate_videoclips(
                        video_only_clips,
                        method="compose",
                        padding=-effective_crossfade
                    )
                else:
                    final_video_clip = concatenate_videoclips(video_only_clips, method="compose")
            except Exception as e:
                logger.error(f"‚ùå Error al concatenar clips: {e}")
                logger.error(f"üìä Intentando concatenar {len(video_only_clips)} clips v√°lidos")
                # Cerrar clips antes de fallar
                for clip in video_only_clips:
                    try:
                        clip.close()
                    except:
                        pass
                raise ValueError(f"Error al concatenar clips de video: {e}")
            total_video_duration = final_video_clip.duration
            
            logger.info(f"üìä Duraci√≥n video concatenado: {total_video_duration:.2f}s | Duraci√≥n audio completo: {total_audio_duration:.2f}s")
            
            # ============================================================
            # LOOPEAR CLIPS VISUALES SI SON M√ÅS CORTOS QUE EL AUDIO
            # ============================================================
            looped_video_temp = None  # Para limpiar despu√©s
            if full_audio_track and total_video_duration < total_audio_duration:
                logger.info(f"üîÑ Video m√°s corto que audio. Loopeando secuencia visual para cubrir {total_audio_duration:.2f}s...")
                loops_needed = int(total_audio_duration / total_video_duration) + 1
                
                # Crear lista de clips repetidos
                looped_video_clips = []
                for i in range(loops_needed):
                    # Hacer una copia del clip concatenado para cada loop
                    looped_video_clips.append(final_video_clip)
                
                # Concatenar los loops
                looped_video_temp = concatenate_videoclips(looped_video_clips, method="compose")
                
                # Cortar al tama√±o exacto del audio
                old_video_clip = final_video_clip
                final_video_clip = looped_video_temp.subclip(0, total_audio_duration)
                total_video_duration = final_video_clip.duration
                
                # Cerrar el clip viejo
                try:
                    old_video_clip.close()
                except:
                    pass
                
                logger.success(f"‚úÖ Video looped: {total_video_duration:.2f}s (cubriendo audio completo)")
            elif full_audio_track and total_video_duration > total_audio_duration:
                # Si el video es m√°s largo, cortarlo al tama√±o del audio
                logger.info(f"‚úÇÔ∏è Video m√°s largo que audio. Cortando video a {total_audio_duration:.2f}s...")
                old_video_clip = final_video_clip
                final_video_clip = final_video_clip.subclip(0, total_audio_duration)
                total_video_duration = total_audio_duration
                # Cerrar el clip viejo
                try:
                    old_video_clip.close()
                except:
                    pass
            elif not full_audio_track:
                # Sin audio: usar duraci√≥n del video o duraci√≥n basada en escenas
                logger.info(f"‚ö†Ô∏è Sin audio disponible. Usando duraci√≥n del video: {total_video_duration:.2f}s")
            
            # ============================================================
            # CALCULAR PUNTOS DE CORTE PARA SFX DE TRANSICI√ìN
            # ============================================================
            transition_cut_points = []
            if full_audio_clips and len(full_audio_clips) > 1:
                # Calcular los tiempos donde terminan los clips (puntos de corte)
                cumulative_time = 0.0
                for idx, audio_clip in enumerate(full_audio_clips):
                    # El punto de corte es donde TERMINA cada clip (excepto el √∫ltimo)
                    if idx < len(full_audio_clips) - 1:  # No agregar corte despu√©s del √∫ltimo clip
                        cumulative_time += audio_clip.duration
                        transition_cut_points.append(cumulative_time)
                logger.info(f"üé¨ Puntos de corte detectados: {len(transition_cut_points)} transiciones")
            
            # ============================================================
            # AGREGAR M√öSICA DE FONDO Y MEZCLAR CON AUDIO COMPLETO
            # Sistema de Ducking: M√∫sica se aten√∫a cuando hay voz
            # ============================================================
            final_audio_composite = full_audio_track
            
            if background_music and Path(background_music).exists():
                try:
                    music_clip = AudioFileClip(background_music)
                    target_duration = total_audio_duration if full_audio_track else total_video_duration
                    
                    # VALIDACI√ìN: Verificar que music_clip no es None
                    if music_clip is None:
                        logger.error("‚ùå music_clip es None despu√©s de cargar")
                        raise ValueError("No se pudo cargar la m√∫sica de fondo")
                    
                    # Asegurar que la m√∫sica cubra toda la duraci√≥n necesaria
                    if music_clip.duration < target_duration:
                        loops_needed = int(target_duration / music_clip.duration) + 1
                        music_clips_looped = [music_clip] * loops_needed
                        try:
                            looped_music = concatenate_audioclips(music_clips_looped)
                            if looped_music is None:
                                logger.error("‚ùå concatenate_audioclips retorn√≥ None para m√∫sica looped")
                                raise ValueError("Error concatenando m√∫sica looped")
                            music_clip = looped_music.subclip(0, target_duration)
                            if music_clip is None:
                                logger.error("‚ùå subclip retorn√≥ None para m√∫sica looped")
                                raise ValueError("Error en subclip de m√∫sica looped")
                        except Exception as e:
                            logger.error(f"‚ùå Error creando m√∫sica looped: {e}")
                            raise
                    
                    # L√ìGICA DE DUCKING (Jerarqu√≠a de Audio)
                    if full_audio_track:
                        # VALIDACI√ìN: Verificar que ambos clips son v√°lidos antes de crear composite
                        if full_audio_track is None:
                            logger.error("‚ùå full_audio_track es None, no se puede mezclar con m√∫sica")
                            final_audio_composite = music_clip
                        elif music_clip is None:
                            logger.error("‚ùå music_clip es None, usando solo full_audio_track")
                            final_audio_composite = full_audio_track
                        else:
                            # Hay voz: Bajar m√∫sica al 10% para que no compita con la narraci√≥n
                            effective_music_volume = 0.1  # 10% - Ducking autom√°tico
                            logger.info("üéµ Mezclando m√∫sica de fondo con pista de audio completa (Ducking activado: m√∫sica al 10%)...")
                            music_clip = music_clip.volumex(effective_music_volume)
                            try:
                                final_audio_composite = CompositeAudioClip([full_audio_track, music_clip])
                                if final_audio_composite is None:
                                    logger.error("‚ùå CompositeAudioClip retorn√≥ None")
                                    final_audio_composite = full_audio_track  # Fallback a solo voz
                                else:
                                    logger.success("‚úÖ M√∫sica de fondo mezclada con voz (m√∫sica atenuada al 10% para claridad)")
                            except Exception as e:
                                logger.error(f"‚ùå Error creando CompositeAudioClip de voz + m√∫sica: {e}")
                                logger.warning("‚ö†Ô∏è Usando solo audio de voz como fallback")
                                final_audio_composite = full_audio_track
                    else:
                        # No hay voz (modo musical o sin narraci√≥n): M√∫sica al volumen configurado o 100%
                        if music_clip is None:
                            logger.error("‚ùå music_clip es None y no hay voz. El video quedar√° sin audio.")
                            final_audio_composite = None
                        else:
                            effective_music_volume = music_volume if music_volume > 0 else 1.0
                            logger.info(f"üéµ Usando m√∫sica de fondo sin narraci√≥n (volumen: {effective_music_volume*100:.0f}%)...")
                            music_clip = music_clip.volumex(effective_music_volume)
                            final_audio_composite = music_clip
                            logger.success(f"‚úÖ M√∫sica de fondo aplicada (sin voz, volumen: {effective_music_volume*100:.0f}%)")
                    
                    music_clip.close()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error mezclando m√∫sica de fondo: {e}. Usando solo audio de narraci√≥n.")
                    if not full_audio_track:
                        logger.warning("‚ö†Ô∏è Sin audio de voz ni m√∫sica. El video quedar√° sin audio.")
                        final_audio_composite = None
            
            # ============================================================
            # INYECTAR EFECTOS DE SONIDO (SFX) EN TRANSICIONES
            # ============================================================
            if final_audio_composite and transition_cut_points and len(transition_cut_points) > 0:
                try:
                    # Buscar archivo de SFX de transici√≥n
                    BASE_DIR = Path(__file__).parent.parent.resolve()
                    sfx_path = BASE_DIR / "assets" / "sfx" / "transition.mp3"
                    
                    if sfx_path.exists():
                        logger.info(f"üéµ Cargando SFX de transici√≥n desde: {sfx_path.name}")
                        transition_sfx = AudioFileClip(str(sfx_path))
                        sfx_duration = transition_sfx.duration
                        sfx_volume = 0.4  # Volumen al 40% para que no tape la voz
                        transition_sfx = transition_sfx.volumex(sfx_volume)
                        
                        # Crear clips de SFX en cada punto de corte
                        sfx_clips = []
                        target_duration = total_audio_duration if full_audio_track else total_video_duration
                        
                        for cut_point in transition_cut_points:
                            # Verificar que el SFX no exceda la duraci√≥n del video
                            if cut_point + sfx_duration <= target_duration:
                                # Crear clip de SFX en el punto de corte
                                sfx_at_cut = transition_sfx.set_start(cut_point)
                                sfx_clips.append(sfx_at_cut)
                                logger.debug(f"‚úÖ SFX agregado en transici√≥n {cut_point:.2f}s")
                            else:
                                logger.debug(f"‚ö†Ô∏è Saltando SFX en {cut_point:.2f}s (exceder√≠a duraci√≥n del video)")
                        
                        if sfx_clips:
                            # VALIDACI√ìN: Filtrar SFX None antes de mezclar
                            valid_sfx_clips = []
                            for i, sfx_clip in enumerate(sfx_clips):
                                if sfx_clip is None:
                                    logger.warning(f"‚ö†Ô∏è SFX clip {i} es None, filtrando...")
                                    continue
                                if not hasattr(sfx_clip, 'duration'):
                                    logger.warning(f"‚ö†Ô∏è SFX clip {i} no tiene duraci√≥n, filtrando...")
                                    continue
                                valid_sfx_clips.append(sfx_clip)
                            
                            if valid_sfx_clips:
                                # VALIDACI√ìN: Verificar que final_audio_composite no es None
                                if final_audio_composite is None:
                                    logger.warning("‚ö†Ô∏è final_audio_composite es None, no se pueden agregar SFX")
                                else:
                                    # Mezclar SFX con el audio compuesto existente
                                    logger.info(f"üîä Mezclando {len(valid_sfx_clips)} efecto(s) de sonido de transici√≥n...")
                                    audio_layers = [final_audio_composite]
                                    audio_layers.extend(valid_sfx_clips)
                                    try:
                                        final_audio_composite = CompositeAudioClip(audio_layers)
                                        if final_audio_composite is None:
                                            logger.error("‚ùå CompositeAudioClip con SFX retorn√≥ None")
                                            # Mantener audio anterior sin SFX
                                        else:
                                            logger.success(f"‚úÖ {len(valid_sfx_clips)} SFX de transici√≥n mezclado(s) exitosamente")
                                    except Exception as e:
                                        logger.error(f"‚ùå Error creando CompositeAudioClip con SFX: {e}")
                                        logger.warning("‚ö†Ô∏è Continuando sin SFX, usando audio anterior")
                            else:
                                logger.warning("‚ö†Ô∏è No hay clips de SFX v√°lidos para mezclar")
                        else:
                            logger.warning("‚ö†Ô∏è No se pudieron crear clips de SFX v√°lidos")
                        
                        # Cerrar el SFX original (ya se copi√≥ en los clips)
                        transition_sfx.close()
                    else:
                        logger.info(f"üí° SFX de transici√≥n no encontrado en: {sfx_path}. Continuando sin efectos de sonido.")
                        logger.info(f"üí° Para agregar SFX, coloca 'transition.mp3' en: assets/sfx/")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error agregando SFX de transici√≥n: {e}. Continuando sin efectos de sonido.")
                    import traceback
                    logger.debug(traceback.format_exc())
            elif transition_cut_points and len(transition_cut_points) > 0:
                logger.debug(f"üí° SFX de transici√≥n disponible pero no hay audio compuesto para mezclar")
            
            # ============================================================
            # AGREGAR AUDIO COMPLETO AL VIDEO FINAL
            # ============================================================
            if final_audio_composite:
                # VALIDACI√ìN CR√çTICA: Verificar que final_audio_composite es v√°lido antes de agregarlo
                if final_audio_composite is None:
                    logger.error("‚ùå final_audio_composite es None, no se puede agregar audio")
                    logger.warning("‚ö†Ô∏è El video quedar√° sin audio")
                    final_audio_composite = None
                elif not hasattr(final_audio_composite, 'duration'):
                    logger.error("‚ùå final_audio_composite no tiene atributo duration")
                    logger.warning("‚ö†Ô∏è El video quedar√° sin audio")
                    try:
                        final_audio_composite.close()
                    except:
                        pass
                    final_audio_composite = None
                else:
                    try:
                        logger.info("üîä Agregando pista de audio completa al video...")
                        
                        # VALIDACI√ìN: Verificar que final_video_clip no es None
                        if final_video_clip is None:
                            logger.error("‚ùå final_video_clip es None, no se puede agregar audio")
                            raise ValueError("final_video_clip es None")
                        
                        # Validar duraci√≥n del audio antes de agregarlo
                        audio_duration_check = final_audio_composite.duration
                        if audio_duration_check <= 0:
                            logger.error(f"‚ùå Duraci√≥n de audio inv√°lida: {audio_duration_check}")
                            raise ValueError(f"Duraci√≥n de audio inv√°lida: {audio_duration_check}")
                        
                        final_video_clip = final_video_clip.set_audio(final_audio_composite)
                        
                        # VALIDACI√ìN POST-SET_AUDIO: Verificar que el clip resultante no es None
                        if final_video_clip is None:
                            logger.error("‚ùå set_audio retorn√≥ None")
                            raise ValueError("set_audio retorn√≥ None")
                        
                        # Asegurar que la duraci√≥n coincida exactamente
                        final_video_clip = final_video_clip.set_duration(total_audio_duration)
                        
                        # VALIDACI√ìN FINAL: Verificar que el clip final es v√°lido
                        if final_video_clip is None:
                            logger.error("‚ùå set_duration retorn√≥ None despu√©s de agregar audio")
                            raise ValueError("set_duration retorn√≥ None")
                        
                        if not hasattr(final_video_clip, 'get_frame'):
                            logger.error("‚ùå final_video_clip no tiene get_frame despu√©s de agregar audio")
                            raise ValueError("final_video_clip no tiene get_frame")
                        
                        logger.success("‚úÖ Audio completo agregado al video")
                        
                        # Cerrar el audio compuesto despu√©s de agregarlo (se copi√≥)
                        try:
                            final_audio_composite.close()
                        except:
                            pass
                        
                        # Cerrar clips de audio individuales
                        for audio_clip in full_audio_clips:
                            try:
                                audio_clip.close()
                            except:
                                pass
                                
                    except Exception as e:
                        logger.error(f"‚ùå Error agregando audio al video: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
                        # Intentar continuar sin audio
                        logger.warning("‚ö†Ô∏è Continuando sin audio debido al error")
                        try:
                            if final_audio_composite:
                                final_audio_composite.close()
                        except:
                            pass
            else:
                logger.warning("‚ö†Ô∏è No hay audio disponible. El video quedar√° sin audio.")
                # Si no hay audio, usar la duraci√≥n del video
                if total_video_duration <= 0:
                    total_video_duration = max(5.0, sum(
                        scene.get("duration") or scene.get("duration_estimate") or 4.0
                        for scene in scenes
                    ))
                final_video_clip = final_video_clip.set_duration(total_video_duration)
            
            final_clip = final_video_clip
            branding_clips_to_close = []
            
            # Asegurar que el video final est√© en la resoluci√≥n objetivo
            # Usar final_width y final_height que pueden venir de target_resolution
            if final_clip.size[0] != final_width or final_clip.size[1] != final_height:
                logger.info(f"Redimensionando a resoluci√≥n objetivo: {final_width}x{final_height}...")
                # Redimensionar y recortar al centro para llenar el canvas sin bordes negros
                final_clip = self._resize_to_format(final_clip, final_width, final_height)
            
            if add_branding:
                target_fps = getattr(final_clip, "fps", 60) or 60
                
                subscribe_path = self._resolve_branding_asset(style_slug, "subscribe.png")
                if subscribe_path and subscribe_path.exists():
                    try:
                        overlay_start = max(0.0, total_video_duration * (2.0 / 3.0))
                        overlay_duration = min(3.0, total_video_duration - overlay_start)
                        if overlay_duration > 0.2:
                            subscribe_clip = (
                                ImageClip(str(subscribe_path))
                                .set_duration(overlay_duration)
                                .resize(width=int(final_clip.w * 0.6))
                                .set_position(("center", int(final_clip.h * 0.7)))
                                .set_start(overlay_start)
                                .fadein(0.5)
                                .fadeout(0.5)
                            )
                            # VALIDACI√ìN: Verificar que ambos clips son v√°lidos antes de crear composite
                            if final_clip is None or subscribe_clip is None:
                                logger.warning(f"‚ö†Ô∏è No se puede crear composite de subscribe: uno de los clips es None")
                            elif not hasattr(final_clip, 'get_frame') or not hasattr(subscribe_clip, 'get_frame'):
                                logger.warning(f"‚ö†Ô∏è No se puede crear composite de subscribe: uno de los clips no tiene get_frame")
                            else:
                                final_clip = CompositeVideoClip([final_clip, subscribe_clip]).set_duration(total_video_duration)
                            subscribe_clip.close()
                            logger.info("üì¢ Overlay 'subscribe' aplicado en el √∫ltimo tercio del video.")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è No se pudo aplicar el overlay 'subscribe.png': {e}")
                
                intro_path = self._resolve_branding_asset(style_slug, "intro.mp4")
                outro_path = self._resolve_branding_asset(style_slug, "outro.mp4")
                concat_sequence = []
                
                def _prepare_brand_clip(path: Path):
                    """
                    Prepara un clip de branding (intro/outro) normaliz√°ndolo para que coincida
                    exactamente con la resoluci√≥n y FPS del video principal.
                    
                    CR√çTICO: Si no se normaliza correctamente, FFmpeg fallar√° al concatenar.
                    """
                    clip = VideoFileClip(str(path))
                    
                    # 1. Silenciar audio del clip de branding (el audio se maneja por separado)
                    clip = clip.without_audio()
                    
                    # 2. Normalizar resoluci√≥n: Redimensionar y recortar al formato exacto
                    clip = self._resize_to_format(clip, final_width, final_height)
                    
                    # 3. Normalizar FPS para que coincida exactamente con el video principal
                    clip = clip.set_fps(target_fps)
                    
                    # 4. Verificar que la resoluci√≥n coincida exactamente
                    current_w, current_h = clip.size
                    if current_w != final_width or current_h != final_height:
                        logger.warning(f"‚ö†Ô∏è El clip de branding no se normaliz√≥ correctamente. Esperado: {final_width}x{final_height}, Obtenido: {current_w}x{current_h}")
                        # Forzar redimensionamiento final
                        clip = clip.resize((final_width, final_height))
                    
                    logger.debug(f"‚úÖ Clip de branding normalizado: {final_width}x{final_height} @ {target_fps} FPS")
                    return clip
                
                if intro_path and intro_path.exists():
                    try:
                        intro_clip = _prepare_brand_clip(intro_path)
                        branding_clips_to_close.append(intro_clip)
                        concat_sequence.append(intro_clip)
                        logger.info("üé¨ Intro branding detectado y agregado.")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è No se pudo cargar intro.mp4: {e}")
                
                concat_sequence.append(final_clip)
                
                if outro_path and outro_path.exists():
                    try:
                        outro_clip = _prepare_brand_clip(outro_path)
                        branding_clips_to_close.append(outro_clip)
                        concat_sequence.append(outro_clip)
                        logger.info("üé¨ Outro branding detectado y agregado.")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è No se pudo cargar outro.mp4: {e}")
                
                if len(concat_sequence) > 1:
                    # VALIDACI√ìN: Filtrar clips None antes de concatenar
                    valid_concat_sequence = []
                    for i, clip in enumerate(concat_sequence):
                        if clip is None:
                            logger.warning(f"‚ö†Ô∏è Clip {i} en concat_sequence es None, filtrando...")
                            continue
                        if not hasattr(clip, 'duration') or not hasattr(clip, 'get_frame'):
                            logger.warning(f"‚ö†Ô∏è Clip {i} en concat_sequence no tiene atributos necesarios, filtrando...")
                            continue
                        try:
                            if clip.duration <= 0:
                                logger.warning(f"‚ö†Ô∏è Clip {i} en concat_sequence tiene duraci√≥n inv√°lida, filtrando...")
                                continue
                            valid_concat_sequence.append(clip)
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Error validando clip {i} en concat_sequence: {e}, filtrando...")
                            continue
                    
                    if len(valid_concat_sequence) == 0:
                        logger.error("‚ùå Todos los clips en concat_sequence son inv√°lidos")
                    elif len(valid_concat_sequence) == 1:
                        final_clip = valid_concat_sequence[0]
                        total_video_duration = final_clip.duration
                        logger.success("‚úÖ Solo un clip v√°lido en concat_sequence")
                    else:
                        final_clip = concatenate_videoclips(valid_concat_sequence, method="compose")
                        total_video_duration = final_clip.duration
                        logger.success("‚úÖ Secuencia final con intro/outro ensamblada correctamente.")
            
            branding_watermark_text = self._load_branding_text(style_slug, "watermark.txt")
            effective_watermark_text = branding_watermark_text or watermark_text
            watermark_image_path = self._resolve_branding_asset(style_slug, "logo.png") or self._resolve_branding_asset(style_slug, "watermark.png")
            
            # Agregar marca de agua si se especifica
            if watermark_image_path or effective_watermark_text:
                try:
                    margin_x = 50
                    margin_y = 100
                    logger.info("Agregando watermark din√°mico.")
                    
                    def _compute_position(element_w: int, element_h: int):
                        if watermark_position == "bottom-right":
                            pos_x = final_width - element_w - margin_x
                            pos_y = final_height - element_h - margin_y
                        elif watermark_position == "top-center":
                            pos_x = (final_width - element_w) / 2
                            pos_y = margin_y
                        elif watermark_position == "bottom-left":
                            pos_x = margin_x
                            pos_y = final_height - element_h - margin_y
                        elif watermark_position == "top-right":
                            pos_x = final_width - element_w - margin_x
                            pos_y = margin_y
                        else:
                            pos_x = final_width - element_w - margin_x
                            pos_y = final_height - element_h - margin_y
                        return pos_x, pos_y
                    
                    if watermark_image_path and watermark_image_path.exists():
                        watermark_img = ImageClip(str(watermark_image_path)).set_duration(final_clip.duration).set_fps(final_clip.fps)
                        target_width_img = min(int(final_width * 0.35), watermark_img.w)
                        watermark_img = watermark_img.resize(width=target_width_img)
                        img_w, img_h = watermark_img.size
                        pos_x, pos_y = _compute_position(img_w, img_h)
                        watermark_img = watermark_img.set_position((pos_x, pos_y), relative=False)
                        # VALIDACI√ìN: Verificar que ambos clips son v√°lidos
                        if final_clip is None or watermark_img is None:
                            logger.warning(f"‚ö†Ô∏è No se puede aplicar watermark de imagen: uno de los clips es None")
                        elif not hasattr(final_clip, 'get_frame') or not hasattr(watermark_img, 'get_frame'):
                            logger.warning(f"‚ö†Ô∏è No se puede aplicar watermark de imagen: uno de los clips no tiene get_frame")
                        else:
                            final_clip = CompositeVideoClip([final_clip, watermark_img])
                            logger.success("‚úÖ Marca de agua por imagen aplicada.")
                    else:
                        fallback_text = effective_watermark_text
                        if not fallback_text:
                            style_handle_slug = self._normalize_style_slug(style_label or style_code or "MetratronTV")
                            if style_handle_slug and style_handle_slug != "general":
                                fallback_text = f"@{style_handle_slug.capitalize()}"
                            else:
                                fallback_text = "@MetratronTV"
                        if not fallback_text.startswith("@"):
                            fallback_text = f"@{fallback_text}"
                        font_candidates = ["Impact", "Arial-Bold", "Arial"]
                        font_size = max(34, int(final_height * 0.035))
                        shadow_offset = 3
                        shadow_kwargs = dict(
                            fontsize=font_size,
                            color='black',
                            stroke_color='black',
                            stroke_width=0,
                            method='label',
                            size=(None, None)
                        )
                        main_kwargs = dict(
                            fontsize=font_size,
                            color='white',
                            stroke_color='black',
                            stroke_width=1,
                            method='label',
                            size=(None, None)
                        )
                        def _create_text_clip(text: str, kwargs: dict):
                            last_error = None
                            for font_name in font_candidates:
                                try:
                                    return TextClip(text, font=font_name, **kwargs)
                                except Exception as exc:
                                    last_error = exc
                                    continue
                            raise last_error or RuntimeError("No fonts available for watermark text")
                        watermark_shadow = _create_text_clip(fallback_text, shadow_kwargs).set_duration(final_clip.duration).set_fps(final_clip.fps)
                        watermark_main = _create_text_clip(fallback_text, main_kwargs).set_duration(final_clip.duration).set_fps(final_clip.fps)
                        
                        text_w, text_h = watermark_main.size
                        pos_x_main, pos_y_main = _compute_position(text_w, text_h)
                        pos_x_shadow = pos_x_main + shadow_offset
                        pos_y_shadow = pos_y_main + shadow_offset
                        
                        watermark_shadow = watermark_shadow.set_position((pos_x_shadow, pos_y_shadow), relative=False)
                        watermark_shadow = watermark_shadow.set_opacity(0.35)
                        watermark_main = watermark_main.set_position((pos_x_main, pos_y_main), relative=False)
                        try:
                            watermark_main = watermark_main.set_opacity(0.6)
                        except (AttributeError, TypeError):
                            logger.debug("set_opacity no disponible para watermark textual.")
                        
                        # VALIDACI√ìN: Verificar que todos los clips son v√°lidos
                        watermark_clips = [c for c in [watermark_shadow, watermark_main] if c is not None]
                        if final_clip is None:
                            logger.warning(f"‚ö†Ô∏è No se puede aplicar watermark de texto: final_clip es None")
                        elif len(watermark_clips) == 0:
                            logger.warning(f"‚ö†Ô∏è No se puede aplicar watermark de texto: todos los clips de texto son None")
                        else:
                            # Verificar que todos tienen get_frame
                            all_valid = all(hasattr(c, 'get_frame') for c in watermark_clips) and hasattr(final_clip, 'get_frame')
                            if not all_valid:
                                logger.warning(f"‚ö†Ô∏è No se puede aplicar watermark de texto: algunos clips no tienen get_frame")
                            else:
                                final_clip = CompositeVideoClip([final_clip] + watermark_clips)
                                logger.success(f"‚úÖ Marca de agua de texto aplicada ({watermark_position}).")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error al agregar marca de agua: {e}. Continuando sin watermark...")
                    import traceback
                    logger.debug(traceback.format_exc())
            
            # Configuraci√≥n Super 1080p para m√°xima calidad en redes sociales
            # Siempre usar bitrate alto (15 Mbps) para evitar pixelaci√≥n en movimiento
            video_bitrate = bitrate or "15000k"  # 15 Mbps - Calidad de estudio
            audio_bitrate = "320k"  # Calidad de estudio para audio
            
            # ============================================================
            # FUNCI√ìN DE VALIDACI√ìN RECURSIVA DE CLIPS
            # ============================================================
            def validar_clip_recursivo(clip, nivel=0, path="root"):
                """Valida un clip y todos sus sub-clips recursivamente"""
                indent = "  " * nivel
                
                if clip is None:
                    logger.error(f"{indent}‚ùå {path}: es None")
                    return False
                
                if not hasattr(clip, 'get_frame'):
                    logger.error(f"{indent}‚ùå {path}: no tiene get_frame, tipo={type(clip)}")
                    return False
                
                # Obtener informaci√≥n b√°sica
                try:
                    clip_type = type(clip).__name__
                    clip_duration = getattr(clip, 'duration', 'N/A')
                    logger.debug(f"{indent}‚úÖ {path}: tipo={clip_type}, duraci√≥n={clip_duration}")
                except Exception as e:
                    logger.warning(f"{indent}‚ö†Ô∏è {path}: error obteniendo info: {e}")
                
                # Si es CompositeVideoClip, revisar sus clips internos
                if hasattr(clip, 'clips') and clip.clips:
                    logger.debug(f"{indent}üìÅ {path}: CompositeVideoClip con {len(clip.clips)} clips internos")
                    for i, sub_clip in enumerate(clip.clips):
                        sub_path = f"{path}.clips[{i}]"
                        if not validar_clip_recursivo(sub_clip, nivel + 1, sub_path):
                            return False
                
                # Si tiene audio, validarlo tambi√©n
                if hasattr(clip, 'audio') and clip.audio is not None:
                    audio_obj = clip.audio
                    logger.debug(f"{indent}üîä {path}.audio: tipo={type(audio_obj).__name__}")
                    
                    # Revisar sub-clips de audio si es CompositeAudioClip
                    if hasattr(audio_obj, 'clips') and audio_obj.clips:
                        logger.debug(f"{indent}  üìÅ Audio tiene {len(audio_obj.clips)} clips internos")
                        for i, audio_clip in enumerate(audio_obj.clips):
                            if audio_clip is None:
                                logger.error(f"{indent}  ‚ùå {path}.audio.clips[{i}]: es None")
                                return False
                            if not hasattr(audio_clip, 'get_frame'):
                                logger.error(f"{indent}  ‚ùå {path}.audio.clips[{i}]: no tiene get_frame, tipo={type(audio_clip)}")
                                return False
                            logger.debug(f"{indent}  ‚úÖ {path}.audio.clips[{i}]: tipo={type(audio_clip).__name__}")
                
                return True
            
            def limpiar_audio_invalido(clip):
                """Remueve audio inv√°lido de un clip recursivamente"""
                if clip is None:
                    return None
                
                # Si es CompositeVideoClip, limpiar sus sub-clips primero
                if hasattr(clip, 'clips') and clip.clips:
                    clips_limpios = []
                    for sub_clip in clip.clips:
                        sub_clip_limpio = limpiar_audio_invalido(sub_clip)
                        if sub_clip_limpio is not None:
                            clips_limpios.append(sub_clip_limpio)
                    
                    if len(clips_limpios) != len(clip.clips):
                        logger.warning(f"‚ö†Ô∏è Se filtraron {len(clip.clips) - len(clips_limpios)} sub-clips inv√°lidos")
                    
                    if clips_limpios:
                        try:
                            return CompositeVideoClip(clips_limpios)
                        except Exception as e:
                            logger.error(f"‚ùå Error recreando CompositeVideoClip: {e}")
                            return None
                    else:
                        return None
                
                # Limpiar audio inv√°lido del clip
                if hasattr(clip, 'audio') and clip.audio is not None:
                    audio_obj = clip.audio
                    
                    # Verificar si el audio es v√°lido
                    audio_invalido = False
                    
                    # Si es CompositeAudioClip, verificar sus clips internos
                    if hasattr(audio_obj, 'clips') and audio_obj.clips:
                        for audio_sub in audio_obj.clips:
                            if audio_sub is None or not hasattr(audio_sub, 'get_frame'):
                                audio_invalido = True
                                logger.warning(f"‚ö†Ô∏è Audio contiene clip None o inv√°lido, removiendo audio")
                                break
                    elif not hasattr(audio_obj, 'get_frame'):
                        audio_invalido = True
                        logger.warning(f"‚ö†Ô∏è Audio no tiene get_frame, removiendo audio")
                    
                    if audio_invalido:
                        try:
                            return clip.without_audio()
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Error removiendo audio: {e}")
                            return clip
                
                return clip
            
            # VALIDACI√ìN FINAL CR√çTICA: Verificar que final_clip es v√°lido antes de renderizar
            if final_clip is None:
                raise ValueError("‚ùå final_clip es None. No se puede renderizar el video.")
            
            # Verificar que tiene los atributos necesarios
            if not hasattr(final_clip, 'duration'):
                raise ValueError("‚ùå final_clip no tiene atributo 'duration'")
            
            if not hasattr(final_clip, 'get_frame'):
                raise ValueError("‚ùå final_clip no tiene atributo 'get_frame'. No es un VideoClip v√°lido.")
            
            # Verificar duraci√≥n v√°lida
            try:
                clip_duration = final_clip.duration
                if clip_duration is None or clip_duration <= 0:
                    raise ValueError(f"‚ùå final_clip tiene duraci√≥n inv√°lida: {clip_duration}")
                logger.info(f"‚úÖ Clip final validado: duraci√≥n {clip_duration:.2f}s, tipo: {type(final_clip)}")
            except Exception as e:
                logger.error(f"‚ùå Error verificando duraci√≥n del clip: {e}")
                raise ValueError(f"No se puede verificar la duraci√≥n del clip: {e}")
            
            # DIAGN√ìSTICO RECURSIVO COMPLETO
            logger.info("üîç Iniciando validaci√≥n recursiva del clip final...")
            if not validar_clip_recursivo(final_clip, nivel=0, path="final_clip"):
                logger.error("‚ùå La validaci√≥n recursiva encontr√≥ elementos None o inv√°lidos")
                logger.warning("üîÑ Intentando limpiar audio inv√°lido...")
                final_clip = limpiar_audio_invalido(final_clip)
                
                if final_clip is None:
                    raise ValueError("‚ùå No se pudo limpiar el clip. Todos los sub-clips son inv√°lidos.")
                
                # Re-validar despu√©s de la limpieza
                logger.info("üîç Re-validando clip despu√©s de la limpieza...")
                if not validar_clip_recursivo(final_clip, nivel=0, path="final_clip_limpio"):
                    raise ValueError("‚ùå El clip a√∫n contiene elementos inv√°lidos despu√©s de la limpieza")
                else:
                    logger.success("‚úÖ Clip validado correctamente despu√©s de la limpieza")
            else:
                logger.success("‚úÖ Validaci√≥n recursiva completada: todos los clips son v√°lidos")
            
            # Renderizar video final con configuraci√≥n optimizada
            logger.info(f"Renderizando video final en {final_width}x{final_height} @ 60 FPS")
            logger.info(f"Bitrate: {video_bitrate} (video) / {audio_bitrate} (audio)")
            
            try:
                final_clip.write_videofile(
                    output_path,
                    codec='libx264',
                    audio_codec='aac',
                    fps=60,  # 60 FPS para m√°xima fluidez en m√≥viles
                    preset='slow',  # Mejor compresi√≥n y calidad (m√°s lento pero mejor resultado)
                    bitrate=video_bitrate,
                    audio_bitrate=audio_bitrate,
                    threads=4,
                    logger=None
                )
            except AttributeError as e:
                error_msg = str(e)
                if "'NoneType' object has no attribute 'get_frame'" in error_msg:
                    logger.error("‚ùå ERROR CR√çTICO: Clip contiene elemento None con get_frame")
                    logger.error(f"   Detalles del clip:")
                    logger.error(f"   - Tipo: {type(final_clip)}")
                    logger.error(f"   - Tiene audio: {hasattr(final_clip, 'audio') and final_clip.audio is not None}")
                    
                    # DIAGN√ìSTICO RECURSIVO COMPLETO - Mostrar TODOS los sub-clips
                    logger.error("üîç Iniciando diagn√≥stico recursivo completo...")
                    def diagnosticar_clip_recursivo(clip, nivel=0, path="final_clip"):
                        """Diagnostica un clip y todos sus sub-clips recursivamente"""
                        indent = "   " + ("  " * nivel)
                        
                        if clip is None:
                            logger.error(f"{indent}‚ùå {path}: es None")
                            return
                        
                        clip_type = type(clip).__name__
                        es_none = clip is None
                        tiene_get_frame = hasattr(clip, 'get_frame')
                        duracion = getattr(clip, 'duration', 'N/A')
                        
                        logger.error(f"{indent}üìπ {path}:")
                        logger.error(f"{indent}   - Tipo: {clip_type}")
                        logger.error(f"{indent}   - Es None: {es_none}")
                        logger.error(f"{indent}   - Tiene get_frame: {tiene_get_frame}")
                        logger.error(f"{indent}   - Duraci√≥n: {duracion}")
                        
                        # Si es CompositeVideoClip, revisar TODOS sus clips internos RECURSIVAMENTE
                        if hasattr(clip, 'clips') and clip.clips:
                            logger.error(f"{indent}   - üìÅ CompositeVideoClip con {len(clip.clips)} clips internos:")
                            for i, sub_clip in enumerate(clip.clips):
                                sub_path = f"{path}.clips[{i}]"
                                # Llamar recursivamente para revisar clips anidados dentro de este sub-clip
                                diagnosticar_clip_recursivo(sub_clip, nivel + 1, sub_path)
                        
                        # Revisar audio si existe
                        if hasattr(clip, 'audio') and clip.audio is not None:
                            audio_obj = clip.audio
                            audio_type = type(audio_obj).__name__
                            logger.error(f"{indent}   - üîä Audio: tipo={audio_type}")
                            
                            # Revisar sub-clips de audio si es CompositeAudioClip
                            if hasattr(audio_obj, 'clips') and audio_obj.clips:
                                logger.error(f"{indent}      - üìÅ Audio tiene {len(audio_obj.clips)} clips internos:")
                                for i, audio_clip in enumerate(audio_obj.clips):
                                    audio_path = f"{path}.audio.clips[{i}]"
                                    if audio_clip is None:
                                        logger.error(f"{indent}      ‚ùå {audio_path}: es None")
                                    else:
                                        audio_clip_type = type(audio_clip).__name__
                                        audio_clip_has_get_frame = hasattr(audio_clip, 'get_frame')
                                        logger.error(f"{indent}      - {audio_path}: tipo={audio_clip_type}, tiene get_frame={audio_clip_has_get_frame}")
                                        if not audio_clip_has_get_frame:
                                            logger.error(f"{indent}      ‚ùå PROBLEMA ENCONTRADO: {audio_path} no tiene get_frame")
                    
                    diagnosticar_clip_recursivo(final_clip, nivel=0, path="final_clip")
                    
                    logger.error("‚ùå No se puede renderizar. El clip contiene componentes None inv√°lidos.")
                    raise ValueError("Clip contiene componentes None inv√°lidos que causan error en get_frame")
                else:
                    # Re-lanzar si es otro tipo de AttributeError
                    raise
            
            # Liberar recursos
            logger.info("Liberando recursos...")
            final_clip.close()
            
            # Cerrar clip looped si existe
            if 'looped_video_temp' in locals() and looped_video_temp:
                try:
                    looped_video_temp.close()
                except:
                    pass
            
            for clip in final_clips:  # Usar final_clips en lugar de clips
                try:
                    if clip is not None:
                        # Cerrar el clip compuesto
                        clip.close()
                        # Cerrar clips originales si existen
                        if hasattr(clip, '_original_video'):
                            try:
                                clip._original_video.close()
                            except:
                                pass
                        if hasattr(clip, '_original_audio'):
                            try:
                                clip._original_audio.close()
                            except:
                                pass
                except:
                    pass
            
            # Cerrar clips de branding (intro/outro)
            for clip in branding_clips_to_close:
                try:
                    clip.close()
                except:
                    pass
            
            # Cerrar clips de video limpios
            for clip in video_only_clips:
                try:
                    if clip is not None:
                        clip.close()
                except:
                    pass
            
            logger.success(f"Video renderizado exitosamente: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Error renderizando video: {e}")
            # Cerrar todos los clips en caso de error
            for clip in clips:
                try:
                    if clip is not None:
                        clip.close()
                except:
                    pass
            raise

